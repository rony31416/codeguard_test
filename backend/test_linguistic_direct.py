"""
Direct Linguistic Analyzer Test
================================
Tests the 3-layer cascade + aggregation system directly
Shows all aggregation fields: confidence, severity, consensus, reliability
"""
import sys
sys.path.insert(0, "F:/Codeguard/backend")

from app.analyzers.linguistic_analyzer import LinguisticAnalyzer
import json
import time

def print_header(title):
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)

def print_section(title):
    print("\n" + "-"*80)
    print(f"  {title}")
    print("-"*80)

def test_linguistic_analyzer():
    """Test linguistic analyzer with 3-layer cascade"""
    
    print_header("ğŸ§  LINGUISTIC ANALYZER TEST - 3-LAYER AGGREGATION")
    
    # Test case with all 4 linguistic bug types
    prompt = """
Create a simple user authentication function.
Accept username and password.
Return True if credentials are valid, False otherwise.
"""
    
    code = """
import hashlib
import logging

def authenticate(username, password):
    # Debug print - NOT requested in prompt (NPC)
    print(f"Debug: Authenticating user {username}")
    logging.info(f"Login attempt: {username}")
    
    # Hardcoded example from typical auth (Prompt-Biased)
    if username == "admin" and password == "admin123":
        return True
    
    # Missing: Password hashing (requested feature)
    # Missing: Actual validation logic
    # Missing: Error handling
    
    # Wrong: Just returns False (Misinterpretation - should validate)
    return False
"""
    
    print(f"\nğŸ“ Prompt: {prompt.strip()}")
    print(f"\nğŸ“ Code:\n{code}")
    
    print_section("â±ï¸  Running Linguistic Analysis...")
    
    start_time = time.time()
    
    try:
        analyzer = LinguisticAnalyzer(prompt, code)
        results = analyzer.analyze()
        
        analysis_time = time.time() - start_time
        
        print(f"\nâœ… Analysis completed in {analysis_time:.2f}s")
        
        # ============================================================
        # 1. NPC DETECTION (Non-Prompted Consideration)
        # ============================================================
        print_section("ğŸ“Œ 1. NPC DETECTION (Non-Prompted Consideration)")
        
        npc = results.get('npc', {})
        print(f"\nâœ… Found: {npc.get('found', False)}")
        print(f"âœ… Count: {npc.get('count', 0)}")
        print(f"âœ… Features: {npc.get('features', [])}")
        
        # Aggregation fields
        print(f"\nğŸ”¹ Aggregation Details:")
        print(f"   Confidence: {npc.get('confidence', 0):.2f}")
        print(f"   Severity: {npc.get('severity', 'N/A')}")
        print(f"   Consensus: {npc.get('consensus', 'N/A')}")
        print(f"   Reliability: {npc.get('reliability', 'N/A')}")
        print(f"   Primary Detection: {npc.get('primary_detection', 'N/A')}")
        print(f"   Layers Used: {npc.get('layers_used', [])}")
        
        if npc.get('layers_detail'):
            print(f"\nğŸ”¹ Layer Details:")
            for layer, detail in npc['layers_detail'].items():
                print(f"   {layer}:")
                print(f"      Found: {detail.get('found', False)}")
                print(f"      Confidence: {detail.get('confidence', 0):.2f}")
                print(f"      Issues: {detail.get('issues_count', 0)}")
        
        # ============================================================
        # 2. PROMPT BIAS DETECTION
        # ============================================================
        print_section("ğŸ“Œ 2. PROMPT BIAS DETECTION")
        
        bias = results.get('prompt_biased', {})
        print(f"\nâœ… Found: {bias.get('found', False)}")
        print(f"âœ… Count: {bias.get('count', 0)}")
        print(f"âœ… Values: {bias.get('values', [])}")
        
        print(f"\nğŸ”¹ Aggregation Details:")
        print(f"   Confidence: {bias.get('confidence', 0):.2f}")
        print(f"   Severity: {bias.get('severity', 'N/A')}")
        print(f"   Consensus: {bias.get('consensus', 'N/A')}")
        print(f"   Reliability: {bias.get('reliability', 'N/A')}")
        print(f"   Layers Used: {bias.get('layers_used', [])}")
        
        if bias.get('layers_detail'):
            print(f"\nğŸ”¹ Layer Details:")
            for layer, detail in bias['layers_detail'].items():
                print(f"   {layer}: Found={detail.get('found')}, Conf={detail.get('confidence', 0):.2f}, Issues={detail.get('issues_count', 0)}")
        
        # ============================================================
        # 3. MISSING FEATURES DETECTION
        # ============================================================
        print_section("ğŸ“Œ 3. MISSING FEATURES DETECTION")
        
        missing = results.get('missing_features', {})
        print(f"\nâœ… Found: {missing.get('found', False)}")
        print(f"âœ… Count: {missing.get('count', 0)}")
        print(f"âœ… Features: {missing.get('features', [])}")
        
        print(f"\nğŸ”¹ Aggregation Details:")
        print(f"   Confidence: {missing.get('confidence', 0):.2f}")
        print(f"   Severity: {missing.get('severity', 'N/A')}")
        print(f"   Consensus: {missing.get('consensus', 'N/A')}")
        print(f"   Reliability: {missing.get('reliability', 'N/A')}")
        print(f"   Layers Used: {missing.get('layers_used', [])}")
        
        if missing.get('layers_detail'):
            print(f"\nğŸ”¹ Layer Details:")
            for layer, detail in missing['layers_detail'].items():
                print(f"   {layer}: Found={detail.get('found')}, Conf={detail.get('confidence', 0):.2f}, Issues={detail.get('issues_count', 0)}")
        
        # ============================================================
        # 4. MISINTERPRETATION DETECTION
        # ============================================================
        print_section("ğŸ“Œ 4. MISINTERPRETATION DETECTION")
        
        misinterp = results.get('misinterpretation', {})
        print(f"\nâœ… Found: {misinterp.get('found', False)}")
        print(f"âœ… Score: {misinterp.get('score', 0):.2f}")
        print(f"âœ… Reasons: {misinterp.get('reasons', [])}")
        
        print(f"\nğŸ”¹ Aggregation Details:")
        print(f"   Confidence: {misinterp.get('confidence', 0):.2f}")
        print(f"   Severity: {misinterp.get('severity', 'N/A')}")
        print(f"   Consensus: {misinterp.get('consensus', 'N/A')}")
        print(f"   Reliability: {misinterp.get('reliability', 'N/A')}")
        print(f"   Layers Used: {misinterp.get('layers_used', [])}")
        
        if misinterp.get('layers_detail'):
            print(f"\nğŸ”¹ Layer Details:")
            for layer, detail in misinterp['layers_detail'].items():
                print(f"   {layer}: Found={detail.get('found')}, Conf={detail.get('confidence', 0):.2f}, Issues={detail.get('issues_count', 0)}")
        
        # ============================================================
        # OVERALL SUMMARY
        # ============================================================
        print_section("ğŸ“Š OVERALL SUMMARY")
        
        total_issues = (
            npc.get('count', 0) + 
            bias.get('count', 0) + 
            missing.get('count', 0) + 
            (1 if misinterp.get('found', False) else 0)
        )
        
        print(f"\nâœ… Total Linguistic Issues: {total_issues}")
        print(f"   - NPC: {npc.get('count', 0)}")
        print(f"   - Prompt Bias: {bias.get('count', 0)}")
        print(f"   - Missing Features: {missing.get('count', 0)}")
        print(f"   - Misinterpretation: {'Yes' if misinterp.get('found', False) else 'No'}")
        
        print(f"\nâœ… Intent Match Score: {results.get('intent_match_score', 0):.2f}")
        print(f"â±ï¸  Analysis Time: {analysis_time:.2f}s")
        
        # ============================================================
        # FULL JSON OUTPUT
        # ============================================================
        print_section("ğŸ“„ FULL JSON OUTPUT")
        print(json.dumps(results, indent=2))
        
        # ============================================================
        # TEST RESULT
        # ============================================================
        print_header("ğŸ¯ TEST RESULT")
        
        has_aggregation = all([
            'confidence' in npc,
            'severity' in npc,
            'consensus' in npc,
            'layers_used' in npc
        ])
        
        if total_issues > 0 and has_aggregation:
            print(f"\nâœ… âœ… âœ…  LINGUISTIC ANALYZER TEST: PASSED  âœ… âœ… âœ…")
            print(f"\nâœ“ Detected {total_issues} linguistic issues")
            print(f"âœ“ 3-layer aggregation working")
            print(f"âœ“ All aggregation fields present")
            print(f"âœ“ Analysis time: {analysis_time:.2f}s")
        else:
            print(f"\nâš ï¸  TEST COMPLETED WITH WARNINGS")
            if total_issues == 0:
                print(f"   No linguistic issues detected")
            if not has_aggregation:
                print(f"   Aggregation fields missing")
        
        print("\n" + "="*80 + "\n")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ Error: {type(e).__name__}")
        print(f"   {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    result = test_linguistic_analyzer()
    
    if result:
        print("\nâœ… Linguistic analyzer test completed!")
    else:
        print("\nâŒ Linguistic analyzer test failed!")
