"""
Test which LLM API is being used (Ollama vs OpenRouter)
"""
import sys
sys.path.insert(0, "F:/Codeguard/backend")

from app.analyzers.linguistic.LLM_response import get_llm

print("\n" + "="*80)
print("ğŸ” Testing LLM API Priority (Ollama â†’ OpenRouter â†’ Skip)")
print("="*80)

llm = get_llm()

# Test API status
print(f"\nâœ… Ollama Enabled: {llm.ollama_enabled}")
print(f"âœ… OpenRouter Enabled: {llm.openrouter_enabled}")
print(f"âœ… Overall LLM Enabled: {llm.enabled}")

# Test simple question
print("\n" + "-"*80)
print("Testing with simple question...")
print("-"*80)

response = llm.ask("What is 2+2? Reply with just the number.")

if response:
    print(f"\nâœ… Response received: {response[:100]}")
    
    # Check which API was used by testing individual APIs
    print("\n" + "-"*80)
    print("ğŸ” Determining which API was used...")
    print("-"*80)
    
    if llm.ollama_enabled:
        ollama_test = llm._ask_ollama("Reply with 'OLLAMA'", max_retries=1)
        if ollama_test:
            print(f"âœ… Ollama is WORKING (likely used for analysis)")
        else:
            print(f"âš ï¸ Ollama test failed")
    
    if llm.openrouter_enabled:
        openrouter_test = llm._ask_openrouter("Reply with 'OPENROUTER'", max_retries=1)
        if openrouter_test:
            print(f"âœ… OpenRouter is WORKING")
        else:
            print(f"âš ï¸ OpenRouter test failed (rate limited)")
else:
    print("\nâŒ No response from any API")

print("\n" + "="*80)
