
==================================================
File: app/analyzers/database.py
==================================================

from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from dotenv import load_dotenv

load_dotenv()

DATABASE_URL = os.getenv("DATABASE_URL")

# Enable pool_pre_ping to gracefully recover from stale connections (e.g., DB restarts)
engine = create_engine(DATABASE_URL, pool_pre_ping=True)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()



==================================================
File: app/analyzers/main.py
==================================================

from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List
import os , json , time

from .database import engine, get_db, Base
from .schemas import CodeAnalysisRequest, AnalysisResponse, FeedbackRequest, BugPatternSchema, ExecutionLogSchema
from .models import Analysis, BugPattern, Feedback, ExecutionLog, LinguisticAnalysis
from .analyzers.static_analyzer import StaticAnalyzer
from .analyzers.dynamic_analyzer import DynamicAnalyzer
from .analyzers.classifier import TaxonomyClassifier
from .analyzers.explainer import ExplainabilityLayer

# Create tables
Base.metadata.create_all(bind=engine)

app = FastAPI(
    title="CodeGuard API",
    description="LLM Bug Taxonomy Classifier & Analyzer",
    version="2.0.0"
)

# CORS - Allow VS Code extension to connect
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, restrict to your extension
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Docker configuration - Use environment variable or fallback to local
DOCKER_HOST = os.getenv("DOCKER_HOST", "unix:///var/run/docker.sock")  # Local Docker by default

@app.get("/")
async def root():
    return {
        "message": "CodeGuard API is running",
        "version": "2.0.0",
        "stages": ["static", "dynamic", "linguistic"],
        "bug_patterns": 10,
        "docker_host": DOCKER_HOST
    }

@app.get("/health")
async def health_check():
    """Health check endpoint for Render"""
    return {"status": "healthy", "backend": "render", "database": "supabase"}

@app.post("/api/analyze", response_model=AnalysisResponse)
def analyze_code(request: CodeAnalysisRequest, db: Session = Depends(get_db)):
    """
    Main analysis endpoint: Three-Stage Hybrid Detection
    
    Stage 1: Static Analysis (AST, Pylint)
    Stage 2: Dynamic Analysis (Docker Sandbox)
    Stage 3: Linguistic Analysis (Prompt-Code Comparison)
    
    Returns: Classified bug patterns from 10 LLM-specific categories
    """
    execution_logs = []
    linguistic_analyzer = None
    
    try:
        print(f"Starting analysis - Prompt: {request.prompt[:50]}..., Code length: {len(request.code)}")
        
        # ===== STAGE 1: Static Analysis =====
        print("Stage 1: Running static analysis...")
        static_start = time.time()
        try:
            static_analyzer = StaticAnalyzer(request.code)
            static_results = static_analyzer.analyze()
            static_time = time.time() - static_start
            
            execution_logs.append({
                "stage": "static",
                "success": True,
                "execution_time": round(static_time, 3),
                "error_message": None,
                "error_type": None
            })
            print(f"✓ Static analysis completed in {static_time:.3f}s")
        except Exception as e:
            static_results = {}
            static_time = time.time() - static_start
            execution_logs.append({
                "stage": "static",
                "success": False,
                "execution_time": round(static_time, 3),
                "error_message": str(e),
                "error_type": type(e).__name__
            })
            print(f"✗ Static analysis failed: {str(e)}")
        
        # ===== STAGE 2: Dynamic Analysis =====
        print("Stage 2: Running dynamic analysis (Docker sandbox)...")
        dynamic_start = time.time()
        try:
            dynamic_analyzer = DynamicAnalyzer(request.code)
            dynamic_results = dynamic_analyzer.analyze()
            dynamic_time = time.time() - dynamic_start
            
            execution_logs.append({
                "stage": "dynamic",
                "success": not dynamic_results.get("execution_error", False),
                "execution_time": round(dynamic_time, 3),
                "error_message": dynamic_results.get("error_message") if dynamic_results.get("execution_error") else None,
                "error_type": None
            })
            print(f"✓ Dynamic analysis completed in {dynamic_time:.3f}s")
        except Exception as e:
            dynamic_results = {
                "execution_success": False,
                "wrong_attribute": {"found": False},
                "wrong_input_type": {"found": False},
                "name_error": {"found": False},
                "other_error": {"found": False}
            }
            dynamic_time = time.time() - dynamic_start
            execution_logs.append({
                "stage": "dynamic",
                "success": False,
                "execution_time": round(dynamic_time, 3),
                "error_message": str(e),
                "error_type": type(e).__name__
            })
            print(f"✗ Dynamic analysis failed: {str(e)}")
        
        # ===== STAGE 3: Linguistic Analysis =====
        print("Stage 3: Running linguistic analysis (prompt-code comparison)...")
        linguistic_start = time.time()
        linguistic_results = {}
        try:
            from .analyzers.linguistic_analyzer import LinguisticAnalyzer
            linguistic_analyzer = LinguisticAnalyzer(request.prompt, request.code)
            linguistic_results = linguistic_analyzer.analyze()
            linguistic_time = time.time() - linguistic_start
            
            execution_logs.append({
                "stage": "linguistic",
                "success": True,
                "execution_time": round(linguistic_time, 3),
                "error_message": None,
                "error_type": None
            })
            print(f"✓ Linguistic analysis completed in {linguistic_time:.3f}s")
        except ImportError:
            # Linguistic analyzer not implemented yet
            linguistic_results = {
                "npc": {"found": False, "features": []},
                "prompt_biased": {"found": False, "values": []},
                "missing_features": {"found": False, "features": []},
                "misinterpretation": {"found": False, "score": 0.0, "reasons": []},
                "intent_match_score": 0.0
            }
            linguistic_time = time.time() - linguistic_start
            execution_logs.append({
                "stage": "linguistic",
                "success": False,
                "execution_time": round(linguistic_time, 3),
                "error_message": "Linguistic analyzer not implemented yet",
                "error_type": "NotImplementedError"
            })
            print("⚠ Linguistic analysis not implemented - using fallback")
        except Exception as e:
            linguistic_results = {
                "npc": {"found": False, "features": []},
                "prompt_biased": {"found": False, "values": []},
                "missing_features": {"found": False, "features": []},
                "misinterpretation": {"found": False, "score": 0.0, "reasons": []},
                "intent_match_score": 0.0
            }
            linguistic_time = time.time() - linguistic_start
            execution_logs.append({
                "stage": "linguistic",
                "success": False,
                "execution_time": round(linguistic_time, 3),
                "error_message": str(e),
                "error_type": type(e).__name__
            })
            print(f"✗ Linguistic analysis failed: {str(e)}")
        
        # ===== STAGE 4: Classification =====
        print("Stage 4: Classifying bug patterns...")
        classifier_start = time.time()
        try:
            classifier = TaxonomyClassifier(static_results, dynamic_results, linguistic_results)
            bug_patterns_list = classifier.classify()
            classifier_time = time.time() - classifier_start
            
            execution_logs.append({
                "stage": "classification",
                "success": True,
                "execution_time": round(classifier_time, 3),
                "error_message": None,
                "error_type": None
            })
            print(f"✓ Classification completed: {len(bug_patterns_list)} patterns detected")
        except Exception as e:
            classifier_time = time.time() - classifier_start
            execution_logs.append({
                "stage": "classification",
                "success": False,
                "execution_time": round(classifier_time, 3),
                "error_message": str(e),
                "error_type": type(e).__name__
            })
            raise HTTPException(status_code=500, detail=f"Classification failed: {str(e)}")
        
        # ===== STAGE 5: Explainability =====
        summary = ExplainabilityLayer.generate_summary(bug_patterns_list)
        overall_severity = classifier.get_overall_severity()
        has_bugs = classifier.has_bugs()
        
        print(f"Overall severity: {overall_severity}/10, Has bugs: {has_bugs}")
        
        # ===== Save to Database =====
        print("Saving analysis to database...")
        analysis = Analysis(
            prompt=request.prompt,
            code=request.code,
            language='python',
            overall_severity=overall_severity,
            has_bugs=has_bugs,
            summary=summary,
            confidence_score=sum(p.confidence for p in bug_patterns_list) / len(bug_patterns_list) if bug_patterns_list else 0.0,
            prompt_keywords=None,  # Removed - not used in current implementation
            code_features=None  # Removed - not used in current implementation
        )
        db.add(analysis)
        db.flush()  # Get analysis_id before adding related records
        
        # Save bug patterns
        for bug_pattern in bug_patterns_list:
            # Determine detection stage
            detection_stage = None
            if bug_pattern.pattern_name in ['Syntax Error', 'Hallucinated Object', 'Incomplete Generation', 'Silly Mistake']:
                detection_stage = 'static'
            elif bug_pattern.pattern_name in ['Wrong Attribute', 'Wrong Input Type']:
                detection_stage = 'dynamic'
            else:
                detection_stage = 'linguistic'
            
            db_bug = BugPattern(
                analysis_id=analysis.analysis_id,
                pattern_name=bug_pattern.pattern_name,
                severity=bug_pattern.severity,
                confidence=bug_pattern.confidence,
                description=bug_pattern.description,
                location=bug_pattern.location,
                fix_suggestion=bug_pattern.fix_suggestion,
                detection_stage=detection_stage
            )
            db.add(db_bug)
        
        # Save execution logs
        for log in execution_logs:
            db_log = ExecutionLog(
                analysis_id=analysis.analysis_id,
                stage=log["stage"],
                success=log["success"],
                error_message=log.get("error_message"),
                error_type=log.get("error_type"),
                traceback=None,
                execution_time=log.get("execution_time")
            )
            db.add(db_log)
        
        # Save linguistic analysis details
        if linguistic_results and linguistic_analyzer:
            ling_analysis = LinguisticAnalysis(
                analysis_id=analysis.analysis_id,
                prompt_intent=json.dumps(linguistic_results.get('missing_features', {})),
                code_intent=json.dumps(linguistic_results.get('npc', {})),
                intent_match_score=linguistic_results.get('intent_match_score', 0.0),
                unprompted_features=json.dumps(linguistic_results.get('npc', {}).get('features', [])),
                missing_features=json.dumps(linguistic_results.get('missing_features', {}).get('features', [])),
                hardcoded_values=json.dumps(linguistic_results.get('prompt_biased', {}).get('values', []))
            )
            db.add(ling_analysis)
        
        db.commit()
        db.refresh(analysis)
        
        print(f"✓ Analysis saved with ID: {analysis.analysis_id}")
        
        # ===== Prepare Response =====
        return AnalysisResponse(
            analysis_id=analysis.analysis_id,
            bug_patterns=[BugPatternSchema.from_orm(bp) for bp in analysis.bug_patterns],
            execution_logs=[ExecutionLogSchema.from_orm(el) for el in analysis.execution_logs],
            overall_severity=overall_severity,
            has_bugs=has_bugs,
            summary=summary,
            created_at=analysis.created_at
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"ERROR: {error_trace}")
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")


@app.post("/api/feedback", response_model=FeedbackRequest)
async def submit_feedback(
    feedback: FeedbackRequest,
    db: Session = Depends(get_db)
):
    """Submit feedback for an analysis"""
    # Check if analysis exists
    analysis = db.query(Analysis).filter(Analysis.analysis_id == feedback.analysis_id).first()
    if not analysis:
        raise HTTPException(status_code=404, detail="Analysis not found")
    
    # Create feedback
    db_feedback = Feedback(
        analysis_id=feedback.analysis_id,
        rating=feedback.rating,
        comment=feedback.comment,
        is_helpful=feedback.is_helpful
    )
    db.add(db_feedback)
    db.commit()
    db.refresh(db_feedback)
    
    return db_feedback


@app.get("/api/history")
def get_history(limit: int = 20, db: Session = Depends(get_db)):
    """
    Get analysis history
    
    Useful for:
    - Viewing past analyses in VS Code extension
    - Tracking analysis trends
    - Research data collection
    """
    analyses = db.query(Analysis).order_by(Analysis.created_at.desc()).limit(limit).all()
    return {
        "total": len(analyses),
        "analyses": [
            {
                "analysis_id": a.analysis_id,
                "prompt": a.prompt[:100] + "..." if len(a.prompt) > 100 else a.prompt,
                "severity": a.overall_severity,
                "has_bugs": a.has_bugs,
                "bug_count": len(a.bug_patterns),
                "created_at": a.created_at.isoformat(),
                "feedback": a.feedback.feedback_type if a.feedback else None
            }
            for a in analyses
        ]
    }


@app.get("/api/analysis/{analysis_id}")
def get_analysis(analysis_id: int, db: Session = Depends(get_db)):
    """
    Get specific analysis details
    
    Returns complete analysis including:
    - Bug patterns
    - Execution logs
    - Linguistic analysis results
    - User feedback
    """
    analysis = db.query(Analysis).filter(Analysis.analysis_id == analysis_id).first()
    if not analysis:
        raise HTTPException(status_code=404, detail="Analysis not found")
    
    return {
        "analysis_id": analysis.analysis_id,
        "prompt": analysis.prompt,
        "code": analysis.code,
        "language": analysis.language,
        "bug_patterns": [BugPatternSchema.from_orm(bp).dict() for bp in analysis.bug_patterns],
        "execution_logs": [ExecutionLogSchema.from_orm(el).dict() for el in analysis.execution_logs],
        "overall_severity": analysis.overall_severity,
        "has_bugs": analysis.has_bugs,
        "summary": analysis.summary,
        "confidence_score": analysis.confidence_score,
        "created_at": analysis.created_at.isoformat(),
        "linguistic_analysis": {
            "intent_match_score": analysis.linguistic_analysis.intent_match_score,
            "unprompted_features": json.loads(analysis.linguistic_analysis.unprompted_features),
            "missing_features": json.loads(analysis.linguistic_analysis.missing_features),
            "hardcoded_values": json.loads(analysis.linguistic_analysis.hardcoded_values)
        } if analysis.linguistic_analysis else None,
        "feedback": {
            "type": analysis.feedback.feedback_type,
            "comment": analysis.feedback.comment,
            "submitted_at": analysis.feedback.submitted_at.isoformat()
        } if analysis.feedback else None
    }


@app.get("/api/stats")
def get_stats(db: Session = Depends(get_db)):
    """
    Get statistics for research analysis
    
    Provides:
    - Total analyses performed
    - Bug pattern frequency distribution
    - Average severity by pattern
    - Detection stage effectiveness
    - User feedback accuracy metrics
    """
    from sqlalchemy import func
    
    # Basic counts
    total_analyses = db.query(Analysis).count()
    total_bugs = db.query(BugPattern).count()
    analyses_with_bugs = db.query(Analysis).filter(Analysis.has_bugs == True).count()
    
    # Bug pattern frequency
    pattern_frequency = db.query(
        BugPattern.pattern_name,
        func.count(BugPattern.bug_pattern_id).label('count')
    ).group_by(BugPattern.pattern_name).order_by(func.count(BugPattern.bug_pattern_id).desc()).all()
    
    # Average severity by pattern
    avg_severity = db.query(
        BugPattern.pattern_name,
        func.avg(BugPattern.severity).label('avg_severity'),
        func.avg(BugPattern.confidence).label('avg_confidence')
    ).group_by(BugPattern.pattern_name).all()
    
    # Detection stage distribution
    stage_distribution = db.query(
        BugPattern.detection_stage,
        func.count(BugPattern.bug_pattern_id).label('count')
    ).group_by(BugPattern.detection_stage).all()
    
    # Feedback statistics
    feedback_stats = db.query(
        Feedback.feedback_type,
        func.count(Feedback.feedback_id).label('count')
    ).group_by(Feedback.feedback_type).all()
    
    # Execution stage success rates
    stage_success = db.query(
        ExecutionLog.stage,
        func.avg(func.cast(ExecutionLog.success, Integer)).label('success_rate'),
        func.avg(ExecutionLog.execution_time).label('avg_time')
    ).group_by(ExecutionLog.stage).all()
    
    return {
        "overview": {
            "total_analyses": total_analyses,
            "total_bugs_detected": total_bugs,
            "analyses_with_bugs": analyses_with_bugs,
            "bug_detection_rate": round(analyses_with_bugs / total_analyses * 100, 2) if total_analyses > 0 else 0
        },
        "pattern_frequency": [
            {
                "pattern": p[0],
                "count": p[1],
                "percentage": round(p[1] / total_bugs * 100, 2) if total_bugs > 0 else 0
            }
            for p in pattern_frequency
        ],
        "average_metrics": [
            {
                "pattern": p[0],
                "avg_severity": round(float(p[1]), 2),
                "avg_confidence": round(float(p[2]), 2)
            }
            for p in avg_severity
        ],
        "detection_stages": [
            {
                "stage": s[0] if s[0] else "unknown",
                "count": s[1]
            }
            for s in stage_distribution
        ],
        "feedback": [
            {
                "type": f[0],
                "count": f[1]
            }
            for f in feedback_stats
        ],
        "stage_performance": [
            {
                "stage": s[0],
                "success_rate": round(float(s[1]) * 100, 2),
                "avg_execution_time": round(float(s[2]), 3) if s[2] else 0
            }
            for s in stage_success
        ]
    }


@app.delete("/api/analysis/{analysis_id}")
def delete_analysis(analysis_id: int, db: Session = Depends(get_db)):
    """
    Delete a specific analysis
    
    Useful for cleaning up test data
    """
    analysis = db.query(Analysis).filter(Analysis.analysis_id == analysis_id).first()
    if not analysis:
        raise HTTPException(status_code=404, detail="Analysis not found")
    
    db.delete(analysis)
    db.commit()
    return {"message": "Analysis deleted successfully", "analysis_id": analysis_id}


@app.get("/api/patterns")
def get_bug_patterns():
    """
    Get information about all 10 bug patterns in the taxonomy
    
    Useful for documentation and extension UI
    """
    patterns = [
        {
            "name": "Syntax Error",
            "stage": "static",
            "severity_range": "8-10",
            "description": "Code cannot be parsed due to syntax violations",
            "example": "Missing colons, unmatched parentheses"
        },
        {
            "name": "Hallucinated Object",
            "stage": "static",
            "severity_range": "7-9",
            "description": "Code references non-existent functions, classes, or variables",
            "example": "PriceCalculator() when class doesn't exist"
        },
        {
            "name": "Incomplete Generation",
            "stage": "static",
            "severity_range": "6-8",
            "description": "Code generation was cut off before completion",
            "example": "Functions with only 'pass' or incomplete assignments"
        },
        {
            "name": "Silly Mistake",
            "stage": "static",
            "severity_range": "5-7",
            "description": "Non-human coding patterns like reversed operands",
            "example": "discount - price instead of price - discount"
        },
        {
            "name": "Wrong Attribute",
            "stage": "dynamic",
            "severity_range": "6-8",
            "description": "Attempting to access non-existent object attributes",
            "example": "dict.key instead of dict['key']"
        },
        {
            "name": "Wrong Input Type",
            "stage": "dynamic",
            "severity_range": "5-7",
            "description": "Function called with inappropriate data type",
            "example": "String concatenation with numeric value"
        },
        {
            "name": "Non-Prompted Consideration (NPC)",
            "stage": "linguistic",
            "severity_range": "4-6",
            "description": "Code includes features not requested in prompt",
            "example": "Adding security checks or sorting not asked for"
        },
        {
            "name": "Prompt-Biased Code",
            "stage": "linguistic",
            "severity_range": "5-7",
            "description": "Hardcoded logic based on prompt examples",
            "example": "if item == 'Example_Item_A'"
        },
        {
            "name": "Missing Corner Case",
            "stage": "linguistic",
            "severity_range": "4-6",
            "description": "Code doesn't handle edge cases properly",
            "example": "No None checks, zero division not handled"
        },
        {
            "name": "Misinterpretation",
            "stage": "linguistic",
            "severity_range": "6-9",
            "description": "Code fundamentally misunderstands the task",
            "example": "Returning string when list was requested"
        }
    ]
    
    return {
        "total_patterns": len(patterns),
        "patterns": patterns
    }


@app.get("/health")
def health_check():
    """
    Health check endpoint for monitoring
    """
    return {
        "status": "healthy",
        "api_version": "2.0.0",
        "timestamp": time.time()
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



==================================================
File: app/analyzers/models.py
==================================================

from sqlalchemy import Column, Integer, String, Text, DateTime, Float, Boolean, ForeignKey
from sqlalchemy.orm import relationship
from .database import Base
from datetime import datetime

class Analysis(Base):
    __tablename__ = "analyses"
    
    analysis_id = Column(Integer, primary_key=True, index=True)
    prompt = Column(Text, nullable=False)
    code = Column(Text, nullable=False)
    language = Column(String(50), default='python')
    overall_severity = Column(Integer, nullable=False)
    has_bugs = Column(Boolean, nullable=False)
    summary = Column(Text)
    confidence_score = Column(Float)
    prompt_keywords = Column(Text)  # NEW: For linguistic analysis
    code_features = Column(Text)    # NEW: For linguistic analysis
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    bug_patterns = relationship("BugPattern", back_populates="analysis", cascade="all, delete-orphan")
    feedbacks = relationship("Feedback", back_populates="analysis", cascade="all, delete-orphan")
    execution_logs = relationship("ExecutionLog", back_populates="analysis", cascade="all, delete-orphan")
    linguistic_analysis = relationship("LinguisticAnalysis", back_populates="analysis", uselist=False, cascade="all, delete-orphan")


class BugPattern(Base):
    __tablename__ = "bug_patterns"
    
    bug_pattern_id = Column(Integer, primary_key=True, index=True)
    analysis_id = Column(Integer, ForeignKey('analyses.analysis_id'), nullable=False)
    pattern_name = Column(String(100), nullable=False)
    severity = Column(Integer, nullable=False)
    confidence = Column(Float, nullable=False)
    description = Column(Text, nullable=False)
    location = Column(String(255))
    fix_suggestion = Column(Text, nullable=False)
    detection_stage = Column(String(50))  # 'static', 'dynamic', 'linguistic'
    
    # Relationship
    analysis = relationship("Analysis", back_populates="bug_patterns")


class Feedback(Base):
    __tablename__ = "feedback"
    
    id = Column(Integer, primary_key=True, index=True)
    analysis_id = Column(Integer, ForeignKey("analyses.analysis_id"), nullable=False)
    rating = Column(Integer, nullable=False)  # 1-5
    comment = Column(Text, nullable=True)
    is_helpful = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationship
    analysis = relationship("Analysis", back_populates="feedbacks")


class ExecutionLog(Base):
    __tablename__ = "execution_logs"
    
    log_id = Column(Integer, primary_key=True, index=True)
    analysis_id = Column(Integer, ForeignKey('analyses.analysis_id'), nullable=False)
    stage = Column(String(50), nullable=False)  # 'static', 'dynamic', 'linguistic', 'classification'
    success = Column(Boolean, nullable=False)
    error_message = Column(Text)
    error_type = Column(String(100))
    traceback = Column(Text)
    execution_time = Column(Float)
    
    # Relationship
    analysis = relationship("Analysis", back_populates="execution_logs")


class LinguisticAnalysis(Base):
    """NEW: Stores Stage 3 linguistic analysis results"""
    __tablename__ = "linguistic_analyses"
    
    linguistic_id = Column(Integer, primary_key=True, index=True)
    analysis_id = Column(Integer, ForeignKey('analyses.analysis_id'), nullable=False)
    prompt_intent = Column(Text)
    code_intent = Column(Text)
    intent_match_score = Column(Float)
    unprompted_features = Column(Text)  # JSON list of NPC features
    missing_features = Column(Text)      # JSON list of missing features
    hardcoded_values = Column(Text)      # JSON list of prompt-biased values
    
    # Relationship
    analysis = relationship("Analysis", back_populates="linguistic_analysis")



==================================================
File: app/analyzers/schemas.py
==================================================

from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

class CodeAnalysisRequest(BaseModel):
    prompt: str
    code: str

class BugPatternSchema(BaseModel):
    pattern_name: str
    severity: int
    confidence: float
    description: str
    location: Optional[str] = None
    fix_suggestion: str
    bug_type: Optional[str] = None

    class Config:
        from_attributes = True

class ExecutionLogSchema(BaseModel):
    stage: str
    success: bool
    error_message: Optional[str] = None
    error_type: Optional[str] = None
    execution_time: Optional[float] = None

    class Config:
        from_attributes = True

class AnalysisResponse(BaseModel):
    analysis_id: int
    bug_patterns: List[BugPatternSchema]
    execution_logs: List[ExecutionLogSchema]
    overall_severity: int
    has_bugs: bool
    summary: str
    created_at: datetime

    class Config:
        from_attributes = True

class FeedbackRequest(BaseModel):
    analysis_id: int
    rating: int  # 1-5 stars
    comment: Optional[str] = None
    is_helpful: bool



==================================================
File: app/analyzers/analyzers/classifier.py
==================================================

from typing import List, Dict, Any
from ..schemas import BugPatternSchema

class TaxonomyClassifier:
    def __init__(self, static_results: Dict, dynamic_results: Dict, linguistic_results: Dict = None):
        self.static = static_results
        self.dynamic = dynamic_results
        self.linguistic = linguistic_results or {}  # NEW: Stage 3 results
        self.bug_patterns = []
    
    def classify(self) -> List[BugPatternSchema]:
        """Map analysis results to bug taxonomy patterns"""
        
        # Stage I: Static Analysis Patterns
        if self.static.get("syntax_error", {}).get("found"):
            self._add_syntax_error()
        
        if self.static.get("hallucinated_objects", {}).get("found"):
            self._add_hallucinated_object()
        
        if self.static.get("incomplete_generation", {}).get("found"):
            self._add_incomplete_generation()
        
        if self.static.get("silly_mistakes", {}).get("found"):
            self._add_silly_mistake()
        
        # Stage II: Dynamic Analysis Patterns
        if self.dynamic.get("wrong_attribute", {}).get("found"):
            self._add_wrong_attribute()
        
        if self.dynamic.get("wrong_input_type", {}).get("found"):
            self._add_wrong_input_type()
        
        # Also check static detection of wrong attributes
        if self.static.get("wrong_attribute", {}).get("found"):
            self._add_wrong_attribute_static()
        
        # Also check static detection of wrong input types
        if self.static.get("wrong_input_type", {}).get("found"):
            if not any(p.pattern_name == "Wrong Input Type" for p in self.bug_patterns):
                self._add_wrong_input_type_static()
        
        # Confirm hallucinated object with NameError
        if self.dynamic.get("name_error", {}).get("found"):
            if not any(p.pattern_name == "Hallucinated Object" for p in self.bug_patterns):
                self._add_hallucinated_object_from_runtime()
        
        # Stage III: Logic and Linguistic Patterns
        if self.linguistic.get("npc", {}).get("found"):
            self._add_npc()
        
        if self.linguistic.get("prompt_biased", {}).get("found"):
            self._add_prompt_biased()
        
        if self.linguistic.get("missing_features", {}).get("found"):
            self._add_missing_features()
        
        if self.static.get("missing_corner_case", {}).get("found"):
            self._add_missing_corner_case()
        
        # Check for misinterpretation (if code has logic issues but no clear category)
        if len(self.bug_patterns) > 3:
            self._add_misinterpretation()
        
        # If no bugs found
        if len(self.bug_patterns) == 0:
            self._add_no_bugs_detected()
        
        return self.bug_patterns
    
    def _add_syntax_error(self):
        error_info = self.static["syntax_error"]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Syntax Error",
            severity=9,
            confidence=1.0,
            description=f"The code contains a syntax error at line {error_info.get('line')}: {error_info.get('error')}",
            location=f"Line {error_info.get('line')}, Column {error_info.get('offset')}",
            fix_suggestion="Review the syntax at the indicated location. Common issues include missing colons, unmatched parentheses, or incorrect indentation."
        ))
    
    def _add_hallucinated_object(self):
        objects = self.static["hallucinated_objects"]["objects"]
        object_names = [obj['name'] if isinstance(obj, dict) else obj for obj in objects]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Hallucinated Object",
            severity=8,
            confidence=0.85,
            description=f"The code references undefined objects that may not exist: {', '.join(object_names)}. LLMs sometimes invent functions, classes or variables that aren't available.",
            location=f"Objects: {', '.join(object_names)}",
            fix_suggestion=f"Verify that {', '.join(object_names)} exist in the imported modules or define them before use. Check official documentation for correct API usage."
        ))
    
    def _add_hallucinated_object_from_runtime(self):
        error_info = self.dynamic["name_error"]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Hallucinated Object",
            severity=8,
            confidence=0.95,
            description=f"Runtime NameError confirms undefined object: {error_info.get('error')}. The LLM generated code referencing non-existent functions or variables.",
            location="See traceback",
            fix_suggestion="Define the missing object or import it from the correct module. Double-check the API documentation."
        ))
    
    def _add_incomplete_generation(self):
        details = self.static["incomplete_generation"]["details"]
        descriptions = [d['description'] for d in details]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Incomplete Generation",
            severity=7,
            confidence=0.90,
            description=f"Code generation appears incomplete. Issues: {'; '.join(descriptions)}. The LLM may have been cut off or reached token limits.",
            location=f"{len(details)} incomplete section(s) detected",
            fix_suggestion="Complete the missing logic based on the function's intended purpose."
        ))
    
    def _add_silly_mistake(self):
        details = self.static["silly_mistakes"]["details"]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Silly Mistake",
            severity=6,
            confidence=0.80,
            description=f"Non-human coding patterns detected. Found {len(details)} issue(s) including: {details[0]['description']}. LLMs sometimes generate logically redundant or reversed operations.",
            location=f"Line {details[0]['line']}",
            fix_suggestion="Review the logic flow. Common issues: reversed operands, wrong data type operations, or redundant conditions."
        ))
    
    def _add_wrong_attribute(self):
        error_info = self.dynamic["wrong_attribute"]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Wrong Attribute",
            severity=7,
            confidence=0.90,
            description=f"AttributeError occurred: {error_info.get('error')}. The LLM attempted to access an attribute or method that doesn't exist on the object.",
            location="See traceback",
            fix_suggestion="Check the object's available attributes using dir() or consult the API documentation. Ensure you're using the correct method name."
        ))
    
    def _add_wrong_attribute_static(self):
        details = self.static["wrong_attribute"]["details"]
        attrs = [f"{d['variable']}.{d['attribute']}" for d in details]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Wrong Attribute",
            severity=7,
            confidence=0.75,
            description=f"Detected incorrect attribute access patterns: {', '.join(attrs)}. Likely treating dictionary keys as object attributes (e.g., dict.key instead of dict['key']).",
            location=f"Found {len(details)} occurrence(s)",
            fix_suggestion=f"Use dictionary access syntax: item['key'] instead of item.key for dictionaries."
        ))
    
    def _add_wrong_input_type(self):
        error_info = self.dynamic["wrong_input_type"]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Wrong Input Type",
            severity=6,
            confidence=0.85,
            description=f"TypeError occurred: {error_info.get('error')}. The function was called with an inappropriate data type or wrong operation on incompatible types.",
            location="See traceback",
            fix_suggestion="Verify the expected input types for the function. Add type conversion or validation before operations. Check for string concatenation with numeric values."
        ))
    
    def _add_wrong_input_type_static(self):
        details = self.static["wrong_input_type"]["details"]
        issues = [f"{d['function']}({d['value']})" for d in details[:3]]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Wrong Input Type",
            severity=6,
            confidence=0.80,
            description=f"Detected wrong input types: {', '.join(issues)}. Passing string literals to numeric functions or vice versa.",
            location=f"Line {details[0]['line']}",
            fix_suggestion=f"Convert types appropriately: use {details[0]['expected_type']} instead of {details[0]['actual_type']}. Remove quotes from numeric values."
        ))
    
    def _add_npc(self):
        npc_data = self.linguistic["npc"]
        features = npc_data.get("features", [])
        count = npc_data.get("count", 0)
        confidence = npc_data.get("confidence", 0.70)
        
        # Format features list for display
        if features:
            features_list = ', '.join(features[:3])  # Show first 3
            if len(features) > 3:
                features_list += f" (+{len(features)-3} more)"
        else:
            features_list = "unrequested code additions"
        
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Non-Prompted Consideration (NPC)",
            severity=5,
            confidence=confidence,
            description=f"The code includes features that weren't requested. Detected {count} unrequested addition(s): {features_list}. LLMs sometimes add security checks, validations, or features beyond the prompt scope.",
            location=f"Multiple locations ({count} issues)",
            fix_suggestion="Remove the unrequested features unless they are actually needed for your use case."
        ))
    
    def _add_prompt_biased(self):
        biased_data = self.linguistic["prompt_biased"]
        values = biased_data.get("values", [])
        count = biased_data.get("count", 0)
        confidence = biased_data.get("confidence", 0.75)
        
        # Format values list for display
        if values:
            values_list = ', '.join(str(v) for v in values[:3])  # Show first 3
            if len(values) > 3:
                values_list += f" (+{len(values)-3} more)"
        else:
            values_list = "hardcoded example values"
        
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Prompt-Biased Code",
            severity=6,
            confidence=confidence,
            description=f"The code contains hardcoded logic based on specific examples from the prompt rather than general solutions. Found {count} instance(s) of example-specific code: {values_list}.",
            location=f"Multiple locations ({count} issues)",
            fix_suggestion="Replace hardcoded values and example-specific logic with general-purpose code that works for all inputs."
        ))
    
    def _add_missing_features(self):
        missing_data = self.linguistic["missing_features"]
        features = missing_data.get("features", [])
        count = missing_data.get("count", 0)
        confidence = missing_data.get("confidence", 0.65)
        
        # Format features list for display
        if features:
            features_list = ', '.join(features[:3])  # Show first 3
            if len(features) > 3:
                features_list += f" (+{len(features)-3} more)"
        else:
            features_list = "requested features"
        
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Missing Features",
            severity=6,
            confidence=confidence,
            description=f"The code is missing features that were requested in the prompt. Detected {count} missing feature(s): {features_list}. The LLM may have overlooked or misunderstood some requirements.",
            location=f"Multiple locations ({count} missing)",
            fix_suggestion="Add the missing features mentioned in the prompt. Review the prompt carefully to ensure all requirements are implemented."
        ))
    
    def _add_missing_corner_case(self):
        details = self.static["missing_corner_case"]["details"]
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Missing Corner Case",
            severity=5,
            confidence=0.65,
            description=f"The code doesn't handle edge cases properly. Detected {len(details)} missing check(s): {details[0]['description']}. Common issues include missing None checks, zero division, or empty input handling.",
            location=f"Multiple locations ({len(details)} issues)",
            fix_suggestion="Add validation for edge cases: check for None inputs, empty lists, zero values in division, and boundary conditions."
        ))
    
    def _add_misinterpretation(self):
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="Misinterpretation",
            severity=7,
            confidence=0.60,
            description="The code has multiple issues suggesting the LLM may have misunderstood the task requirements. This is the most common and difficult-to-diagnose bug pattern.",
            location="Multiple issues across the code",
            fix_suggestion="Review the prompt and compare with the generated code logic. The fundamental approach may need to be rewritten."
        ))
    
    def _add_no_bugs_detected(self):
        self.bug_patterns.append(BugPatternSchema(
            pattern_name="No Bugs Detected",
            severity=0,
            confidence=0.70,
            description="Static and dynamic analysis did not detect any obvious bugs. However, logic errors or missing corner cases may still exist and require test case validation.",
            location="N/A",
            fix_suggestion="Consider writing comprehensive test cases to validate correctness, especially for edge cases."
        ))
    
    def get_overall_severity(self) -> int:
        """Calculate overall severity score"""
        if not self.bug_patterns:
            return 0
        return max(p.severity for p in self.bug_patterns)
    
    def has_bugs(self) -> bool:
        """Check if any actual bugs were found"""
        return any(p.pattern_name != "No Bugs Detected" for p in self.bug_patterns)



==================================================
File: app/analyzers/analyzers/dynamic_analyzer.py
==================================================

import docker
import json
import tempfile
import os
import platform
from typing import Dict, Any

class DynamicAnalyzer:
    def __init__(self, code: str, timeout: int = 5):
        self.code = code
        self.timeout = timeout
        try:
            self.client = docker.from_env()
        except Exception as e:
            print(f"Docker client initialization failed: {e}")
            self.client = None
    
    def analyze(self) -> Dict[str, Any]:
        """Execute code in Docker sandbox and capture runtime errors"""
        # If Docker is not available, skip dynamic analysis
        if not self.client:
            return {
                "execution_error": False,
                "error_message": "Docker not available - skipping dynamic analysis",
                "wrong_attribute": {"found": False},
                "wrong_input_type": {"found": False},
                "name_error": {"found": False},
                "other_error": {"found": False}
            }
        
        try:
            result = self._execute_in_sandbox()
            return self._classify_runtime_errors(result)
        except Exception as e:
            print(f"Dynamic analysis error: {e}")
            return {
                "execution_error": True,
                "error_message": str(e),
                "wrong_attribute": {"found": False},
                "wrong_input_type": {"found": False},
                "name_error": {"found": False},
                "other_error": {"found": False}
            }
    
    def _execute_in_sandbox(self) -> Dict[str, Any]:
        """Execute code in isolated Docker container"""
        # Escape the code properly for JSON
        escaped_code = self.code.replace('\\', '\\\\').replace('"', '\\"').replace('\n', '\\n').replace('\r', '').replace('\t', '\\t')
        
        # Create a wrapper script that captures exceptions
        wrapper_code = f'''import sys
import json
import traceback

code_to_run = """{escaped_code}"""

result = {{
    "success": False,
    "output": "",
    "error": None,
    "error_type": None,
    "traceback": None
}}

try:
    exec(code_to_run)
    result["success"] = True
    result["output"] = "Code executed successfully"
except AttributeError as e:
    result["error_type"] = "AttributeError"
    result["error"] = str(e)
    result["traceback"] = traceback.format_exc()
except TypeError as e:
    result["error_type"] = "TypeError"
    result["error"] = str(e)
    result["traceback"] = traceback.format_exc()
except NameError as e:
    result["error_type"] = "NameError"
    result["error"] = str(e)
    result["traceback"] = traceback.format_exc()
except Exception as e:
    result["error_type"] = type(e).__name__
    result["error"] = str(e)
    result["traceback"] = traceback.format_exc()

print(json.dumps(result))
'''
        
        # Create temporary file with wrapper code
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as f:
            f.write(wrapper_code)
            temp_file = f.name
        
        try:
            # Get the directory and filename separately
            temp_dir = os.path.dirname(temp_file)
            temp_filename = os.path.basename(temp_file)
            
            # For Windows, convert path format
            if platform.system() == 'Windows':
                # Convert Windows path to Docker volume format
                temp_dir = temp_dir.replace('\\', '/')
                if ':' in temp_dir:
                    # Convert C:\path to /c/path
                    drive, path = temp_dir.split(':', 1)
                    temp_dir = f'/{drive.lower()}{path}'
            
            print(f"Mounting: {temp_dir} -> /code")
            print(f"Executing: {temp_filename}")
            
            # Run in Docker container
            container = self.client.containers.run(
                'python:3.10-slim',
                f'python /code/{temp_filename}',
                volumes={temp_dir: {'bind': '/code', 'mode': 'ro'}},
                working_dir='/code',
                network_disabled=True,
                mem_limit='128m',
                cpu_quota=50000,
                remove=True,
                detach=True
            )
            
            # Wait for execution with timeout
            try:
                exit_code = container.wait(timeout=self.timeout)
                output = container.logs().decode('utf-8')
            except Exception as timeout_error:
                # Container timed out
                try:
                    container.stop(timeout=1)
                    container.remove()
                except:
                    pass
                return {
                    "success": False,
                    "error": "Execution timed out",
                    "error_type": "TimeoutError"
                }
            
            # Parse JSON result
            try:
                result = json.loads(output)
            except:
                result = {
                    "success": False,
                    "output": output,
                    "error": "Failed to parse execution result",
                    "error_type": "ParseError"
                }
            
            return result
            
        except docker.errors.ContainerError as e:
            print(f"Container error: {e}")
            return {
                "success": False,
                "error": str(e),
                "error_type": "ContainerError"
            }
        except docker.errors.ImageNotFound:
            print("Docker image not found. Please build it first.")
            return {
                "success": False,
                "error": "Docker image 'python:3.10-slim' not found. Please run: docker pull python:3.10-slim",
                "error_type": "ImageNotFound"
            }
        except Exception as e:
            print(f"Execution error: {e}")
            import traceback
            print(traceback.format_exc())
            return {
                "success": False,
                "error": str(e),
                "error_type": "ExecutionError"
            }
        finally:
            try:
                os.unlink(temp_file)
            except:
                pass
    
    def _classify_runtime_errors(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Classify runtime errors into bug patterns"""
        classification = {
            "execution_success": result.get("success", False),
            "wrong_attribute": {"found": False},
            "wrong_input_type": {"found": False},
            "name_error": {"found": False},
            "other_error": {"found": False}
        }
        
        if not result.get("success"):
            error_type = result.get("error_type")
            error_msg = result.get("error", "")
            traceback = result.get("traceback", "")
            
            if error_type == "AttributeError":
                classification["wrong_attribute"] = {
                    "found": True,
                    "error": error_msg,
                    "traceback": traceback
                }
            elif error_type == "TypeError":
                classification["wrong_input_type"] = {
                    "found": True,
                    "error": error_msg,
                    "traceback": traceback
                }
            elif error_type == "NameError":
                classification["name_error"] = {
                    "found": True,
                    "error": error_msg,
                    "traceback": traceback
                }
            else:
                classification["other_error"] = {
                    "found": True,
                    "error_type": error_type,
                    "error": error_msg,
                    "traceback": traceback
                }
        
        return classification



==================================================
File: app/analyzers/analyzers/explainer.py
==================================================

from typing import List
from ..schemas import BugPatternSchema

class ExplainabilityLayer:
    @staticmethod
    def generate_summary(bug_patterns: List[BugPatternSchema]) -> str:
        """Generate a human-readable summary of the analysis"""
        if not bug_patterns or all(p.pattern_name == "No Bugs Detected" for p in bug_patterns):
            return "No obvious bugs detected in static and dynamic analysis. Code appears syntactically correct and executes without runtime errors."
        
        bug_count = len([p for p in bug_patterns if p.pattern_name != "No Bugs Detected"])
        max_severity = max(p.severity for p in bug_patterns)
        
        severity_label = "Critical" if max_severity >= 8 else "High" if max_severity >= 6 else "Medium" if max_severity >= 4 else "Low"
        
        pattern_names = [p.pattern_name for p in bug_patterns if p.pattern_name != "No Bugs Detected"]
        
        summary = f"Found {bug_count} bug pattern(s) with {severity_label} severity.\n\nDetected patterns:\n"
        for i, pattern in enumerate(pattern_names, 1):
            summary += f"{i}. {pattern}\n"
        summary += "\nReview the detailed analysis below for explanations and fix suggestions."
        
        return summary



==================================================
File: app/analyzers/analyzers/linguistic_analyzer.py
==================================================

"""
Stage 3: Linguistic Analysis - Compares prompt intent with code implementation

Main orchestrator for all linguistic detectors:
1. NPC (Non-Prompted Consideration) - unrequested features
2. Prompt-Biased Code - hardcoded example values
3. Missing Features - features requested but not implemented
4. Misinterpretation - fundamental intent mismatch
"""

import ast
import os
from typing import Dict, Any

# Import specialized detectors
from .linguistic.npc_detector import NPCDetector
from .linguistic.prompt_bias_detector import PromptBiasDetector
from .linguistic.missing_feature_detector import MissingFeatureDetector
from .linguistic.misinterpretation_detector import MisinterpretationDetector
from .linguistic.utils.similarity_calculator import SimilarityCalculator


class LinguisticAnalyzer:
    """
    Stage 3: Linguistic Analysis Orchestrator
    Coordinates all specialized detectors with NLP support
    """
    
    def __init__(self, prompt: str, code: str):
        self.prompt = prompt
        self.code = code
        self.code_ast = self._safe_parse_ast()
        
        # Initialize similarity calculator
        self.similarity_calculator = SimilarityCalculator()
        
        # Initialize all detectors
        self.npc_detector = NPCDetector(prompt, code, self.code_ast)
        self.prompt_bias_detector = PromptBiasDetector(prompt, code, self.code_ast)
        self.missing_feature_detector = MissingFeatureDetector(prompt, code, self.code_ast)
        self.misinterpretation_detector = MisinterpretationDetector(prompt, code, self.code_ast)
    
    def analyze(self) -> Dict[str, Any]:
        """Run all linguistic analyses"""
        results = {
            "npc": self.npc_detector.detect(),
            "prompt_biased": self.prompt_bias_detector.detect(),
            "missing_features": self.missing_feature_detector.detect(),
            "misinterpretation": self.misinterpretation_detector.detect(),
            "intent_match_score": self.similarity_calculator.calculate_similarity(
                self.prompt, self.code
            )
        }
        return results
    
    def _safe_parse_ast(self) -> ast.AST:
        """Safely parse AST"""
        try:
            return ast.parse(self.code)
        except SyntaxError:
            return None



==================================================
File: app/analyzers/analyzers/static_analyzer.py
==================================================

import ast
import re
import sys
from io import StringIO
from typing import List, Dict, Any, Set
from pyflakes import api as pyflakes_api
from pyflakes import reporter as pyflakes_reporter

class StaticAnalyzer:
    def __init__(self, code: str):
        self.code = code
        self.lines = code.split('\n')
        self.tree = None
        self.issues = []
    
    def analyze(self) -> Dict[str, Any]:
        """Run all static analysis checks - fault tolerant"""
        results = {
            "syntax_error": self._check_syntax(),
            "hallucinated_objects": self._check_hallucinated_objects(),
            "incomplete_generation": self._check_incomplete_generation(),
            "silly_mistakes": self._check_silly_mistakes(),
            "undefined_names": self._check_undefined_names(),
            "wrong_attribute": self._check_wrong_attribute_static(),
            "wrong_input_type": self._check_wrong_input_type_static(),
            "prompt_biased": self._check_prompt_biased_code(),
            "npc": self._check_non_prompted_consideration(),
            "missing_corner_case": self._check_missing_corner_cases()
        }
        return results
    
    def _check_syntax(self) -> Dict[str, Any]:
        """Check for syntax errors using AST parsing"""
        try:
            self.tree = ast.parse(self.code)
            return {"found": False, "error": None}
        except SyntaxError as e:
            # Still try to get partial AST for further analysis
            return {
                "found": True,
                "error": str(e),
                "line": e.lineno,
                "offset": e.offset,
                "text": e.text
            }
        except Exception as e:
            return {
                "found": True,
                "error": f"Parse error: {str(e)}",
                "line": None,
                "offset": None,
                "text": None
            }
    
    def _try_parse_partial(self) -> ast.AST:
        """Try to parse code with syntax errors removed"""
        if self.tree:
            return self.tree
        
        # Try to parse by removing problematic lines
        for i in range(len(self.lines)):
            try:
                # Remove lines one by one to get partial AST
                temp_lines = self.lines[:i] + self.lines[i+1:]
                temp_code = '\n'.join(temp_lines)
                return ast.parse(temp_code)
            except:
                continue
        return None
    
    def _check_hallucinated_objects(self) -> Dict[str, Any]:
        """Detect potentially undefined variables/functions via pattern matching"""
        hallucinated = []
        
        # Pattern matching approach (works even with syntax errors)
        patterns = [
            (r'(\w+)\s*=\s*(\w+)\(\)', 'function_call'),  # x = SomeClass()
            (r'from\s+(\w+)\s+import', 'import_statement'),
            (r'import\s+(\w+)', 'import_statement'),
        ]
        
        # Hardcoded Python built-ins (more reliable than dir(__builtins__) on cloud platforms)
        builtins = {
            # Built-in functions
            'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes',
            'callable', 'chr', 'classmethod', 'compile', 'complex', 'delattr',
            'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'filter',
            'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr',
            'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass',
            'iter', 'len', 'list', 'locals', 'map', 'max', 'memoryview', 'min',
            'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property',
            'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice',
            'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type',
            'vars', 'zip', '__import__',
            # Built-in exceptions
            'BaseException', 'Exception', 'ArithmeticError', 'AssertionError',
            'AttributeError', 'BlockingIOError', 'BrokenPipeError', 'BufferError',
            'BytesWarning', 'ChildProcessError', 'ConnectionError', 'ConnectionAbortedError',
            'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning',
            'EOFError', 'EnvironmentError', 'FileExistsError', 'FileNotFoundError',
            'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError',
            'ImportError', 'ImportWarning', 'IndentationError', 'IndexError',
            'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt',
            'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError',
            'NotADirectoryError', 'NotImplementedError', 'OSError', 'OverflowError',
            'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError',
            'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError',
            'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError',
            'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError',
            'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError',
            'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning',
            'ValueError', 'Warning', 'ZeroDivisionError',
            # Built-in constants
            'False', 'True', 'None', 'NotImplemented', 'Ellipsis', '__debug__',
        }
        
        common_modules = {'math', 'os', 'sys', 're', 'json', 'time', 'datetime', 
                         'random', 'collections', 'itertools', 'functools', 'numpy', 'pandas',
                         'logging', 'pathlib', 'io', 'typing', 'copy', 'pickle'}
        
        # Look for suspicious class instantiations (skip comments)
        class_pattern = re.compile(r'([A-Z][a-zA-Z0-9]*)\s*\(')
        for i, line in enumerate(self.lines):
            # Skip comment lines
            stripped = line.strip()
            if stripped.startswith('#'):
                continue
            # Remove inline comments before matching
            code_part = line.split('#')[0]
            matches = class_pattern.findall(code_part)
            for match in matches:
                if match not in builtins and match not in common_modules:
                    # Check if it's defined in the code
                    if not any(f'class {match}' in l for l in self.lines):
                        hallucinated.append({
                            "name": match,
                            "line": i + 1,
                            "type": "class"
                        })
        
        # Also check with AST if available
        tree = self._try_parse_partial()
        if tree:
            defined_names = set()
            used_names = set()
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    defined_names.add(node.name)
                    # Add function parameters to defined names
                    for arg in node.args.args:
                        defined_names.add(arg.arg)
                    # Add keyword-only args
                    for arg in node.args.kwonlyargs:
                        defined_names.add(arg.arg)
                    # Add *args and **kwargs
                    if node.args.vararg:
                        defined_names.add(node.args.vararg.arg)
                    if node.args.kwarg:
                        defined_names.add(node.args.kwarg.arg)
                elif isinstance(node, ast.ClassDef):
                    defined_names.add(node.name)
                elif isinstance(node, ast.Assign):
                    for target in node.targets:
                        if isinstance(target, ast.Name):
                            defined_names.add(target.id)
                # FIX: Add loop variables as defined
                elif isinstance(node, ast.For):
                    if isinstance(node.target, ast.Name):
                        defined_names.add(node.target.id)
                    elif isinstance(node.target, ast.Tuple):
                        for elt in node.target.elts:
                            if isinstance(elt, ast.Name):
                                defined_names.add(elt.id)
                # FIX: Add with statement variables as defined
                elif isinstance(node, ast.With):
                    for item in node.items:
                        if item.optional_vars and isinstance(item.optional_vars, ast.Name):
                            defined_names.add(item.optional_vars.id)
                # FIX: Add comprehension variables as defined
                elif isinstance(node, (ast.ListComp, ast.SetComp, ast.DictComp, ast.GeneratorExp)):
                    for generator in node.generators:
                        if isinstance(generator.target, ast.Name):
                            defined_names.add(generator.target.id)
                        elif isinstance(generator.target, ast.Tuple):
                            for elt in generator.target.elts:
                                if isinstance(elt, ast.Name):
                                    defined_names.add(elt.id)
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        name = alias.asname if alias.asname else alias.name
                        defined_names.add(name)
                elif isinstance(node, ast.ImportFrom):
                    for alias in node.names:
                        name = alias.asname if alias.asname else alias.name
                        defined_names.add(name)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Load):
                    used_names.add(node.id)
            
            for name in used_names:
                if name not in defined_names and name not in builtins and name not in common_modules:
                    if not any(h['name'] == name for h in hallucinated):
                        hallucinated.append({
                            "name": name,
                            "line": None,
                            "type": "variable"
                        })
        
        return {
            "found": len(hallucinated) > 0,
            "objects": hallucinated
        }
    
    def _check_incomplete_generation(self) -> Dict[str, Any]:
        """Check for incomplete code generation patterns"""
        incomplete = []
        
        # Pattern 1: Variables assigned to nothing
        for i, line in enumerate(self.lines):
            # Check for incomplete assignments like "final_val ="
            if re.search(r'\w+\s*=\s*$', line.strip()):
                incomplete.append({
                    "type": "incomplete_assignment",
                    "line": i + 1,
                    "description": "Assignment with no value"
                })
        
        # Pattern 2: Functions with only pass or docstring
        tree = self._try_parse_partial()
        if tree:
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    if len(node.body) == 0:
                        incomplete.append({
                            "type": "empty_function",
                            "line": node.lineno,
                            "description": f"Function '{node.name}' has no body"
                        })
                    elif len(node.body) == 1:
                        first_stmt = node.body[0]
                        if isinstance(first_stmt, ast.Pass):
                            incomplete.append({
                                "type": "pass_only",
                                "line": node.lineno,
                                "description": f"Function '{node.name}' contains only 'pass'"
                            })
        
        # Pattern 3: Incomplete strings or comments suggesting cutoff
        for i, line in enumerate(self.lines):
            if '...' in line or 'TODO' in line or 'FIXME' in line:
                incomplete.append({
                    "type": "incomplete_marker",
                    "line": i + 1,
                    "description": "Code contains incomplete markers"
                })
            # Comments suggesting incomplete code
            if '# missing' in line.lower() or '# stopped' in line.lower() or '# incomplete' in line.lower():
                incomplete.append({
                    "type": "incomplete_comment",
                    "line": i + 1,
                    "description": "Comment indicates incomplete code"
                })
        
        # Pattern 4: Incomplete loop logic (e.g., while loop with only one counter modified)
        if tree:
            for node in ast.walk(tree):
                if isinstance(node, ast.While):
                    # Check if there are comparison variables in the test
                    loop_vars = set()
                    if isinstance(node.test, ast.Compare):
                        if isinstance(node.test.left, ast.Name):
                            loop_vars.add(node.test.left.id)
                        for comp in node.test.comparators:
                            if isinstance(comp, ast.Name):
                                loop_vars.add(comp.id)
                    
                    # Check which variables are modified in the loop body
                    modified_vars = set()
                    for stmt in ast.walk(node):
                        if isinstance(stmt, ast.AugAssign) and isinstance(stmt.target, ast.Name):
                            modified_vars.add(stmt.target.id)
                        elif isinstance(stmt, ast.Assign):
                            for target in stmt.targets:
                                if isinstance(target, ast.Name):
                                    modified_vars.add(target.id)
                    
                    # If loop has 2+ comparison variables but only 1 is modified, it's likely incomplete
                    if len(loop_vars) >= 2 and len(modified_vars) == 1 and modified_vars.issubset(loop_vars):
                        incomplete.append({
                            "type": "incomplete_loop",
                            "line": node.lineno,
                            "description": f"While loop modifies only {modified_vars.pop()} but compares multiple variables"
                        })
        
        return {
            "found": len(incomplete) > 0,
            "details": incomplete
        }
    
    def _check_silly_mistakes(self) -> Dict[str, Any]:
        """Detect non-human coding patterns"""
        silly_mistakes = []
        
        # Pattern 1: Reversed operands in calculations
        # Look for patterns like "rate - price" instead of "price - rate"
        for i, line in enumerate(self.lines):
            # Detect suspicious subtractions with small values
            if re.search(r'(discount|rate|percent)\s*-\s*(\w+)', line):
                silly_mistakes.append({
                    "type": "reversed_operands",
                    "line": i + 1,
                    "description": "Suspicious operation: subtracting larger value from smaller (possible reversed operands)"
                })
        
        # Pattern 2: String concatenation with non-string
        for i, line in enumerate(self.lines):
            if re.search(r'["\'].*["\']\s*\+\s*\w+(?!\()', line):
                # Check if the variable looks numeric
                if re.search(r'(rate|price|count|value|num)', line):
                    silly_mistakes.append({
                        "type": "type_concatenation",
                        "line": i + 1,
                        "description": "Attempting string concatenation with likely numeric value"
                    })
        
        # Pattern 3: Identical if/else branches (AST)
        tree = self._try_parse_partial()
        if tree:
            for node in ast.walk(tree):
                if isinstance(node, ast.If):
                    if node.orelse and len(node.orelse) > 0:
                        try:
                            if_body_dump = [ast.dump(stmt) for stmt in node.body]
                            if len(node.orelse) == 1 and isinstance(node.orelse[0], ast.If):
                                continue
                            else:
                                else_body_dump = [ast.dump(stmt) for stmt in node.orelse]
                            
                            if if_body_dump == else_body_dump and len(if_body_dump) > 0:
                                silly_mistakes.append({
                                    "type": "identical_branches",
                                    "line": node.lineno,
                                    "description": "If and else branches contain identical code"
                                })
                        except:
                            continue
        
        return {
            "found": len(silly_mistakes) > 0,
            "details": silly_mistakes
        }
    
    def _check_undefined_names(self) -> Dict[str, Any]:
        """Use pyflakes to detect undefined names"""
        warnings = StringIO()
        reporter = pyflakes_reporter.Reporter(warnings, sys.stderr)
        
        try:
            pyflakes_api.check(self.code, '<string>', reporter)
            warning_text = warnings.getvalue()
            
            undefined = []
            for line in warning_text.split('\n'):
                if 'undefined name' in line:
                    undefined.append(line.strip())
            
            return {
                "found": len(undefined) > 0,
                "warnings": undefined
            }
        except Exception as e:
            return {"found": False, "warnings": [], "error": str(e)}
    
    def _check_wrong_attribute_static(self) -> Dict[str, Any]:
        """Detect wrong attribute access patterns (static analysis)"""
        wrong_attrs = []
        
        # Pattern: dict.attribute instead of dict['key']
        # Common mistake: item.cost instead of item['cost']
        for i, line in enumerate(self.lines):
            # Look for variable.attribute where variable looks like a dict
            dict_access = re.findall(r'(\w+)\.(\w+)', line)
            for var, attr in dict_access:
                # If accessing common dict keys as attributes
                if attr in ['cost', 'price', 'name', 'value', 'id', 'key']:
                    wrong_attrs.append({
                        "variable": var,
                        "attribute": attr,
                        "line": i + 1,
                        "description": f"Accessing '{attr}' as attribute instead of dictionary key"
                    })
        
        return {
            "found": len(wrong_attrs) > 0,
            "details": wrong_attrs
        }
    
    def _check_wrong_input_type_static(self) -> Dict[str, Any]:
        """Detect wrong input types in function calls (static analysis)"""
        wrong_types = []
        
        # Pattern: String literal passed to numeric functions
        numeric_functions = {
            'sqrt', 'pow', 'log', 'exp', 'sin', 'cos', 'tan',
            'ceil', 'floor', 'round', 'abs', 'int', 'float'
        }
        
        tree = self._try_parse_partial()
        if tree:
            for node in ast.walk(tree):
                if isinstance(node, ast.Call):
                    # Check if calling a numeric function
                    func_name = None
                    if isinstance(node.func, ast.Name):
                        func_name = node.func.id
                    elif isinstance(node.func, ast.Attribute):
                        func_name = node.func.attr
                    
                    if func_name in numeric_functions:
                        # Check if passing string arguments
                        for arg in node.args:
                            if isinstance(arg, ast.Constant) and isinstance(arg.value, str):
                                wrong_types.append({
                                    "function": func_name,
                                    "expected_type": "numeric",
                                    "actual_type": "string",
                                    "value": arg.value,
                                    "line": node.lineno,
                                    "description": f"Passing string '{arg.value}' to numeric function {func_name}()"
                                })
        
        return {
            "found": len(wrong_types) > 0,
            "details": wrong_types
        }
    
    def _check_prompt_biased_code(self) -> Dict[str, Any]:
        """Detect hardcoded values from examples"""
        biased_code = []
        
        # Look for hardcoded specific values
        for i, line in enumerate(self.lines):
            # Check for hardcoded strings in comparisons (but skip common patterns)
            if re.search(r'==\s*["\']Example_', line):
                biased_code.append({
                    "line": i + 1,
                    "description": "Hardcoded check for example-specific value"
                })
            
            # Check for hardcoded file names from examples (e.g., "orders_demo.csv")
            if re.search(r'==\s*["\'][^"\']*(demo|example|sample|test)[^"\']*(\.(csv|txt|json))?["\']', line, re.IGNORECASE):
                biased_code.append({
                    "line": i + 1,
                    "description": "Hardcoded example filename in comparison"
                })
        
        return {
            "found": len(biased_code) > 0,
            "details": biased_code
        }
    
    def _check_non_prompted_consideration(self) -> Dict[str, Any]:
        """Detect features not requested in prompt"""
        npc_issues = []
        
        # Pattern 1: Security checks that weren't asked for
        for i, line in enumerate(self.lines):
            if 'raise' in line and any(word in line.lower() for word in ['admin', 'security', 'permission', 'auth']):
                npc_issues.append({
                    "line": i + 1,
                    "description": "Added security/authentication logic not requested"
                })
        
        # Pattern 2: Validation checks beyond requirements
        for i, line in enumerate(self.lines):
            if re.search(r'if.*>\s*\d{3,}.*raise', line):
                npc_issues.append({
                    "line": i + 1,
                    "description": "Added arbitrary threshold validation not requested"
                })
        
        return {
            "found": len(npc_issues) > 0,
            "details": npc_issues
        }
    
    def _check_missing_corner_cases(self) -> Dict[str, Any]:
        """Detect missing critical edge case handling (very conservative)"""
        missing_cases = []
        
        # Only check for CRITICAL missing corner cases, not defensive programming
        tree = self._try_parse_partial()
        
        # Check for division operations without ANY zero/empty checking
        if tree:
            for i, line in enumerate(self.lines):
                if '/' in line and 'if' not in line:
                    # Check if there's ANY protection against division by zero
                    # Look for checks in surrounding context (wider range)
                    context_start = max(0, i-5)
                    context_end = min(len(self.lines), i+3)
                    context_lines = '\n'.join(self.lines[context_start:context_end])
                    
                    # Check for various forms of protection
                    has_protection = any([
                        '!= 0' in context_lines,
                        '== 0' in context_lines,
                        'if not' in context_lines,  # Empty check
                        'len(' in context_lines and ('if' in context_lines or 'return' in context_lines),  # Length check
                        'ZeroDivisionError' in context_lines,  # Exception handling
                    ])
                    
                    if not has_protection:
                        # Only report if it's clearly risky (dividing by len() without checks)
                        if 'len(' in line or 'count' in line.lower():
                            missing_cases.append({
                                "line": i + 1,
                                "description": "Division operation without zero check"
                            })
        
        return {
            "found": len(missing_cases) > 0,
            "details": missing_cases
        }



==================================================
File: app/analyzers/analyzers/linguistic/base_detector.py
==================================================

"""
Base detector class with shared utilities
"""
import ast
from typing import Set, Dict, Any, List
from abc import ABC, abstractmethod


class BaseDetector(ABC):
    """Abstract base class for all linguistic detectors"""
    
    # Common stop words
    STOP_WORDS = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',
        'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
        'should', 'could', 'may', 'might', 'must', 'can', 'this', 'that'
    }
    
    # Programming verbs
    ACTION_VERBS = {
        'create', 'write', 'implement', 'calculate', 'compute', 'return',
        'get', 'fetch', 'find', 'check', 'validate', 'sort', 'filter',
        'parse', 'process', 'handle', 'update', 'delete', 'add', 'remove'
    }
    
    def __init__(self, prompt: str, code: str, code_ast: ast.AST = None):
        self.prompt = prompt
        self.prompt_lower = prompt.lower()
        self.code = code
        self.code_lower = code.lower()
        self.code_ast = code_ast if code_ast else self._safe_parse_ast()
    
    @abstractmethod
    def detect(self) -> Dict[str, Any]:
        """Each detector must implement this method"""
        pass
    
    def _safe_parse_ast(self) -> ast.AST:
        """Safely parse AST"""
        try:
            return ast.parse(self.code)
        except SyntaxError:
            return None
    
    def _filter_stop_words(self, words: Set[str]) -> Set[str]:
        """Remove common stop words"""
        return {w for w in words if w.lower() not in self.STOP_WORDS}



==================================================
File: app/analyzers/analyzers/linguistic/LLM_response.py
==================================================

"""
Dual LLM API Integration - Ollama (Primary) + OpenRouter (Fallback)
Fallback Chain: Ollama → OpenRouter → Skip LLM

Primary: Ollama Cloud (gpt-oss:20b-cloud) - Fast & Reliable
Fallback: OpenRouter (google/gemma-3-12b-it:free) - Free tier
"""

import os
import requests
import time
from typing import Dict, Any, Optional
from dotenv import load_dotenv

load_dotenv()

# Try to import Ollama client (graceful fail if not installed)
OLLAMA_AVAILABLE = False
try:
    from ollama import Client
    OLLAMA_AVAILABLE = True
except ImportError:
    print("⚠️ Ollama client not installed. Install with: pip install ollama")
    Client = None


class LLM:
    """Dual LLM wrapper with Ollama (primary) and OpenRouter (fallback)."""
    
    def __init__(self):
        # Ollama configuration
        self.ollama_api_key = os.getenv("OLLAMA_API_KEY", "")
        self.ollama_enabled = OLLAMA_AVAILABLE and bool(self.ollama_api_key and self.ollama_api_key != "*****")
        self.ollama_model = "gpt-oss:20b-cloud"
        self.ollama_client = None
        
        # OpenRouter configuration (fallback)
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY", "")
        self.openrouter_enabled = bool(self.openrouter_api_key and self.openrouter_api_key != "*****")
        self.openrouter_url = "https://openrouter.ai/api/v1/chat/completions"
        self.openrouter_model = "google/gemma-3-12b-it:free"
        
        # Initialize Ollama client if available
        if self.ollama_enabled:
            try:
                self.ollama_client = Client(
                    host='https://ollama.com',
                    headers={'Authorization': f'Bearer {self.ollama_api_key}'}
                )
            except Exception as e:
                print(f"⚠️ Failed to initialize Ollama client: {e}")
                self.ollama_enabled = False
        
        # Overall LLM status
        self.enabled = self.ollama_enabled or self.openrouter_enabled
        
        # Debug logging
        if not self.enabled:
            print(f"❌ LLM Disabled: OLLAMA_AVAILABLE={OLLAMA_AVAILABLE}, Ollama Key={'[SET]' if self.ollama_api_key else '[MISSING]'}, OpenRouter Key={'[SET]' if self.openrouter_api_key else '[MISSING]'}")
        else:
            print(f"✓ LLM Enabled: Ollama={self.ollama_enabled}, OpenRouter={self.openrouter_enabled}")
    
    def ask(self, prompt: str, max_retries: int = 2) -> Optional[str]:
        """
        Ask LLM with fallback chain: Ollama → OpenRouter → None
        
        Args:
            prompt: Question to ask the LLM
            max_retries: Number of retries per API (default: 2)
        
        Returns:
            LLM response string or None if all APIs fail
        """
        if not self.enabled:
            return None
        
        # Try Ollama first (primary)
        if self.ollama_enabled:
            response = self._ask_ollama(prompt, max_retries)
            if response:
                return response
            print("⚠️ Ollama failed, falling back to OpenRouter...")
        
        # Fallback to OpenRouter
        if self.openrouter_enabled:
            response = self._ask_openrouter(prompt, max_retries)
            if response:
                return response
            print("⚠️ OpenRouter failed, skipping LLM analysis...")
        
        # Both APIs failed
        return None
    
    def _ask_ollama(self, prompt: str, max_retries: int = 2) -> Optional[str]:
        """Ask Ollama Cloud API with streaming."""
        if not self.ollama_enabled or not self.ollama_client:
            return None
        
        messages = [{"role": "user", "content": prompt}]
        
        for attempt in range(max_retries):
            try:
                stream = self.ollama_client.chat(
                    model=self.ollama_model,
                    messages=messages,
                    stream=True
                )
                
                full_response = ""
                for part in stream:
                    content = part.message.content
                    full_response += content
                
                if full_response:
                    return full_response
                
            except Exception as e:
                print(f"⚠️ Ollama attempt {attempt + 1}/{max_retries} failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(1)  # Brief pause before retry
        
        return None
    
    def _ask_openrouter(self, prompt: str, max_retries: int = 2) -> Optional[str]:
        """Ask OpenRouter API (fallback)."""
        if not self.openrouter_enabled:
            return None
        
        headers = {
            "Authorization": f"Bearer {self.openrouter_api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.openrouter_model,
            "messages": [{"role": "user", "content": prompt}]
        }
        
        for attempt in range(max_retries):
            try:
                r = requests.post(
                    self.openrouter_url,
                    headers=headers,
                    json=payload,
                    timeout=60
                )
                
                if r.status_code == 200:
                    return r.json()["choices"][0]["message"]["content"]
                
                elif r.status_code == 429:
                    wait = 2 ** attempt
                    print(f"⚠️ OpenRouter rate limited. Retry in {wait}s...")
                    time.sleep(wait)
                
                else:
                    print(f"⚠️ OpenRouter error {r.status_code}: {r.text[:100]}")
                    
            except Exception as e:
                print(f"⚠️ OpenRouter attempt {attempt + 1}/{max_retries} failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
        
        return None
    
    def is_alive(self) -> Dict[str, Any]:
        """Test if LLM APIs are working (both Ollama and OpenRouter)."""
        if not self.enabled:
            return {"status": "disabled", "message": "No API keys configured"}
        
        results = {
            "ollama": {"enabled": self.ollama_enabled, "working": False},
            "openrouter": {"enabled": self.openrouter_enabled, "working": False}
        }
        
        # Test Ollama
        if self.ollama_enabled:
            try:
                response = self._ask_ollama("Reply with OK", max_retries=1)
                if response:
                    results["ollama"]["working"] = True
                    results["ollama"]["response"] = response[:50]
            except Exception as e:
                results["ollama"]["error"] = str(e)
        
        # Test OpenRouter
        if self.openrouter_enabled:
            try:
                response = self._ask_openrouter("Reply with OK", max_retries=1)
                if response:
                    results["openrouter"]["working"] = True
                    results["openrouter"]["response"] = response[:50]
            except Exception as e:
                results["openrouter"]["error"] = str(e)
        
        # Determine overall status
        if results["ollama"]["working"] or results["openrouter"]["working"]:
            status = "alive"
            message = f"Working: {'Ollama' if results['ollama']['working'] else ''} {'OpenRouter' if results['openrouter']['working'] else ''}".strip()
        else:
            status = "error"
            message = "All LLM APIs failed"
        
        return {
            "status": status,
            "message": message,
            "apis": results
        }
    
    def analyze_code(self, prompt: str, code: str) -> Dict[str, Any]:
        """Analyze code for bugs using fallback chain."""
        if not self.enabled:
            return {"success": False, "error": "No API enabled", "api_used": None}
        
        question = f"""Analyze this code for bugs.

USER PROMPT:
{prompt}

GENERATED CODE:
{code}

Find these bug types:
1. NPC (Non-Prompted Considerations): Debug prints, hardcoded values, missing error handling
2. Prompt Bias: Hardcoded examples from the prompt
3. Missing Features: Features user expected but not implemented
4. Misinterpretation: Code doesn't match user intent

Return ONLY valid JSON in this format:
{{
    "npc_issues": ["list of NPC bugs found"],
    "prompt_bias_issues": ["list of prompt-biased bugs"],
    "missing_features": ["list of missing features"],
    "misinterpretation": ["list of misinterpretations"],
    "severity": 0-10,
    "summary": "brief summary"
}}"""
        
        try:
            # Try Ollama first
            api_used = None
            response = None
            
            if self.ollama_enabled:
                response = self._ask_ollama(question, max_retries=1)
                if response:
                    api_used = "ollama"
            
            # Fallback to OpenRouter
            if not response and self.openrouter_enabled:
                response = self._ask_openrouter(question, max_retries=1)
                if response:
                    api_used = "openrouter"
            
            if response:
                return {
                    "success": True,
                    "analysis": response,
                    "api_used": api_used,
                    "model": self.ollama_model if api_used == "ollama" else self.openrouter_model
                }
            else:
                return {
                    "success": False,
                    "error": "All LLM APIs failed",
                    "api_used": None
                }
        
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "api_used": None
            }


# Singleton
_llm = None

def get_llm():
    """Get LLM singleton instance."""
    global _llm
    if _llm is None:
        _llm = LLM()
    return _llm


if __name__ == "__main__":
    """Quick test for dual LLM system"""
    llm = get_llm()
    
    print("=" * 80)
    print("🧪 Testing Dual LLM System (Ollama + OpenRouter)")
    print("=" * 80)
    print(f"\n✅ Ollama Enabled: {llm.ollama_enabled}")
    print(f"✅ OpenRouter Enabled: {llm.openrouter_enabled}")
    print(f"✅ Overall Status: {'ENABLED' if llm.enabled else 'DISABLED'}")
    
    if not llm.enabled:
        print("\n⚠️ No LLM APIs configured. Add API keys to .env file.")
        exit(1)
    
    print("\n" + "-" * 80)
    print("Testing API Connectivity...")
    print("-" * 80)
    
    result = llm.is_alive()
    print(f"\nStatus: {result['status']}")
    print(f"Message: {result['message']}")
    print(f"\nAPI Details:")
    for api_name, api_info in result.get('apis', {}).items():
        print(f"  {api_name.upper()}:")
        print(f"    Enabled: {api_info['enabled']}")
        print(f"    Working: {api_info['working']}")
        if 'response' in api_info:
            print(f"    Response: {api_info['response']}")
        if 'error' in api_info:
            print(f"    Error: {api_info['error']}")
    
    if result['status'] == 'alive':
        print("\n" + "-" * 80)
        print("Testing Code Analysis...")
        print("-" * 80)
        
        analysis = llm.analyze_code(
            prompt="Create a function to add two numbers",
            code="""def add(a, b):
    print(f"Adding {a} and {b}")  # debug print
    result = a + b
    return result

result = add(5, 3)  # hardcoded example"""
        )
        
        if analysis['success']:
            print(f"\n✅ Analysis successful!")
            print(f"API Used: {analysis['api_used'].upper()}")
            print(f"Model: {analysis['model']}")
            print(f"\nResponse:\n{analysis['analysis'][:500]}...")
        else:
            print(f"\n❌ Analysis failed: {analysis['error']}")
    
    print("\n" + "=" * 80)




==================================================
File: app/analyzers/analyzers/linguistic/misinterpretation_detector.py
==================================================

"""
Detect fundamental misunderstanding of the task
Enhanced with 3-layer evidence → LLM verdict architecture
"""
import re
import ast
from typing import Dict, Any, List
from .base_detector import BaseDetector
from .utils.similarity_calculator import SimilarityCalculator
from .layers import RuleEngine, ASTAnalyzer, LLMReasoner


class MisinterpretationDetector(BaseDetector):
    """Detect if code fundamentally misunderstood the prompt using 3-layer cascade"""
    
    def __init__(self, prompt: str, code: str, code_ast: ast.AST = None):
        super().__init__(prompt, code, code_ast)
        self.similarity_calculator = SimilarityCalculator()
        
        # Initialize 3-layer architecture (NO aggregator needed)
        self.rule_engine = RuleEngine()
        self.ast_analyzer = ASTAnalyzer()
        self.llm_reasoner = LLMReasoner()
    
    def detect(self) -> Dict[str, Any]:
        """
        NEW 3-Stage Flow:
        Stage 1: Rule Engine collects evidence
        Stage 2: AST Analyzer collects evidence  
        Stage 3: LLM makes final verdict based on combined evidence
        """
        # LAYER 1: Rule Engine - Collect evidence (Fast pattern matching ~10ms)
        layer1_evidence = self.rule_engine.detect_misinterpretation(self.code, self.prompt)
        
        # LAYER 2: AST Analyzer - Collect evidence (Structural verification ~50ms)
        layer2_evidence = self.ast_analyzer.analyze_return_type_mismatch(self.code, self.prompt) if self.code_ast else None
        
        # LAYER 3: LLM makes final verdict based on Layer 1 & 2 evidence (~300ms)
        final_verdict = self.llm_reasoner.final_verdict(
            prompt=self.prompt,
            code=self.code,
            layer1_evidence=layer1_evidence,
            layer2_evidence=layer2_evidence,
            detector_type='misinterpretation'
        )
        
        return final_verdict
    
    def _detect_return_print_mismatch(self) -> tuple:
        """Check if code prints when it should return"""
        # Prompt asks for return
        asks_for_return = any(kw in self.prompt_lower for kw in ['return', 'output', 'give'])
        
        if asks_for_return and self.code_ast:
            has_return = any(isinstance(node, ast.Return) for node in ast.walk(self.code_ast) if isinstance(node, ast.Return) and node.value)
            has_print = 'print(' in self.code
            
            if has_print and not has_return:
                return (0.4, "prints instead of returning")
        
        return (0.0, None)
    
    def _detect_wrong_data_type(self) -> tuple:
        """Check for wrong return type"""
        # Expected types from prompt
        type_mapping = {
            'list': ['list', 'array'],
            'dict': ['dict', 'dictionary', 'object'],
            'string': ['string', 'str', 'text'],
            'number': ['int', 'integer', 'float', 'number'],
            'bool': ['bool', 'boolean', 'true', 'false']
        }
        
        # Find expected type
        expected_type = None
        for canonical, keywords in type_mapping.items():
            if any(kw in self.prompt_lower for kw in keywords):
                expected_type = canonical
                break
        
        if not expected_type:
            return (0.0, None)
        
        # Check return type in code
        if self.code_ast:
            for node in ast.walk(self.code_ast):
                if isinstance(node, ast.Return) and node.value:
                    # Check if returning wrong type
                    if isinstance(node.value, ast.Constant):
                        actual_type = type(node.value.value).__name__
                        
                        # Map Python types
                        actual_canonical = {
                            'str': 'string',
                            'int': 'number',
                            'float': 'number',
                            'list': 'list',
                            'dict': 'dict',
                            'bool': 'bool'
                        }.get(actual_type, actual_type)
                        
                        if actual_canonical != expected_type:
                            return (0.3, f"returns {actual_canonical} but expects {expected_type}")
        
        return (0.0, None)
    
    def _detect_missing_core_function(self) -> tuple:
        """Check if main function definition is missing"""
        # Extract function name from prompt
        func_pattern = r'(?:function|write|create|implement)\s+(?:a\s+)?(?:function\s+)?(?:called\s+)?["\']?(\w+)["\']?'
        matches = re.findall(func_pattern, self.prompt_lower)
        
        if matches and self.code_ast:
            requested_func = matches[0]
            
            # Get all function names in code
            actual_funcs = set()
            for node in ast.walk(self.code_ast):
                if isinstance(node, ast.FunctionDef):
                    actual_funcs.add(node.name.lower())
            
            if requested_func not in actual_funcs:
                return (0.3, f"missing requested function '{requested_func}'")
        
        return (0.0, None)
    
    def _detect_wrong_approach(self) -> tuple:
        """Detect if using completely wrong algorithm"""
        # Check for algorithm-specific keywords
        algorithm_keywords = {
            'sort': ['sorted', 'sort(', '.sort'],
            'search': ['search', 'find', 'index'],
            'filter': ['filter', 'comprehension', '['],
            'sum': ['sum(', '+='],
            'count': ['count(', 'len(']
        }
        
        for algo, keywords in algorithm_keywords.items():
            if algo in self.prompt_lower:
                # Check if ANY of the expected keywords appear in code
                if not any(kw in self.code for kw in keywords):
                    return (0.2, f"'{algo}' requested but not found in implementation")
        
        return (0.0, None)



==================================================
File: app/analyzers/analyzers/linguistic/missing_feature_detector.py
==================================================

"""
Detect features mentioned in prompt but missing in code
Enhanced with 3-layer evidence → LLM verdict architecture
"""
import re
import ast
from typing import Dict, Any, List, Set
from .base_detector import BaseDetector
from .utils.keyword_extractor import KeywordExtractor
from .utils.ast_analyzer import ASTAnalyzer as UtilsASTAnalyzer
from .layers import RuleEngine, ASTAnalyzer, LLMReasoner


class MissingFeatureDetector(BaseDetector):
    """Detect features requested but not implemented using 3-layer cascade"""
    
    def __init__(self, prompt: str, code: str, code_ast: ast.AST = None):
        super().__init__(prompt, code, code_ast)
        self.keyword_extractor = KeywordExtractor()
        self.utils_ast_analyzer = UtilsASTAnalyzer(self.code_ast) if self.code_ast else None
        
        # Initialize 3-layer architecture (NO aggregator needed)
        self.rule_engine = RuleEngine()
        self.ast_analyzer = ASTAnalyzer()
        self.llm_reasoner = LLMReasoner()
    
    def detect(self) -> Dict[str, Any]:
        """
        NEW 3-Stage Flow:
        Stage 1: Rule Engine collects evidence
        Stage 2: AST Analyzer collects evidence  
        Stage 3: LLM makes final verdict based on combined evidence
        """
        # LAYER 1: Rule Engine - Collect evidence (Fast pattern matching ~10ms)
        layer1_evidence = self.rule_engine.detect_missing_features(self.code, self.prompt)
        
        # LAYER 2: AST Analyzer - Collect evidence (Structural verification ~50ms)
        layer2_evidence = self.ast_analyzer.verify_missing_features(self.code, self.prompt) if self.code_ast else None
        
        # LAYER 3: LLM makes final verdict based on Layer 1 & 2 evidence (~300ms)
        final_verdict = self.llm_reasoner.final_verdict(
            prompt=self.prompt,
            code=self.code,
            layer1_evidence=layer1_evidence,
            layer2_evidence=layer2_evidence,
            detector_type='missing_feature'
        )
        
        return final_verdict
    
    def _detect_missing_actions(self) -> List[str]:
        """Check if requested actions are implemented"""
        missing = []
        
        # Extract action verbs from prompt
        requested_actions = self.keyword_extractor.extract_action_verbs(self.prompt)
        
        # Check if each action is in code
        for action in requested_actions:
            # Look for the action word in code (case insensitive)
            if action not in self.code_lower:
                # Also check if function with that name exists
                if self.ast_analyzer:
                    functions = self.ast_analyzer.get_function_names()
                    if action not in functions:
                        missing.append(f"'{action}' action not implemented")
                else:
                    missing.append(f"'{action}' action not implemented")
        
        return missing
    
    def _detect_missing_data_types(self) -> List[str]:
        """Check if requested data types are used"""
        missing = []
        
        # Extract data types from prompt
        requested_types = self.keyword_extractor.extract_data_types(self.prompt)
        
        # Check if types are mentioned in code
        for dtype in requested_types:
            if dtype not in self.code_lower:
                missing.append(f"'{dtype}' data type not used")
        
        return missing
    
    def _detect_missing_returns(self) -> List[str]:
        """Check if function returns value when expected"""
        missing = []
        
        # Check if prompt asks for return
        return_keywords = ['return', 'output', 'result', 'give back']
        asks_for_return = any(kw in self.prompt_lower for kw in return_keywords)
        
        if asks_for_return and self.code_ast:
            # Check if code has return statements
            has_return = False
            for node in ast.walk(self.code_ast):
                if isinstance(node, ast.Return):
                    if node.value is not None:  # Not just 'return' without value
                        has_return = True
                        break
            
            if not has_return:
                # Check if it prints instead
                has_print = 'print(' in self.code
                if has_print:
                    missing.append("should return value but only prints")
                else:
                    missing.append("missing return statement")
        
        return missing
    
    def _is_error_handling_requested(self) -> bool:
        """Check if prompt asks for error handling"""
        error_keywords = ['error', 'exception', 'handle', 'validate', 'check']
        return any(kw in self.prompt_lower for kw in error_keywords)
    
    def _detect_missing_error_handling(self) -> List[str]:
        """Check if requested error handling exists"""
        missing = []
        
        if self.ast_analyzer:
            if not self.ast_analyzer.has_try_except():
                missing.append("error handling requested but not implemented")
        
        return missing



==================================================
File: app/analyzers/analyzers/linguistic/npc_detector.py
==================================================

"""
Detect features added that weren't requested (NPC - Non-Prompted Consideration)
Enhanced with 3-layer evidence → LLM verdict architecture
"""
import ast
from typing import Dict, Any, List
from .base_detector import BaseDetector
from .utils.keyword_extractor import KeywordExtractor
from .layers import RuleEngine, ASTAnalyzer, LLMReasoner


class NPCDetector(BaseDetector):
    """Detect Non-Prompted Considerations using 3-layer cascade"""
    
    # Common NPC patterns (kept for backward compatibility)
    NPC_PATTERNS = {
        'sorted': 'sorting',
        'sort(': 'sorting',
        '.sort': 'sorting',
        'raise': 'exception raising',
        'Exception': 'exception handling',
        'admin': 'admin checks',
        'auth': 'authentication',
        'permission': 'permission checks',
        'role': 'role-based access',
        'log': 'logging',
        'logger': 'logging',
        'print(': 'debugging output',
        'assert': 'assertions',
        'validate': 'validation',
        'cache': 'caching',
        '@lru_cache': 'memoization',
        'lock': 'thread locking',
        'mutex': 'synchronization',
        'semaphore': 'synchronization'
    }
    
    def __init__(self, prompt: str, code: str, code_ast: ast.AST = None):
        super().__init__(prompt, code, code_ast)
        self.keyword_extractor = KeywordExtractor()
        self.prompt_keywords = self.keyword_extractor.extract_from_prompt(prompt)
        
        # Initialize 3-layer architecture (NO aggregator needed)
        self.rule_engine = RuleEngine()
        self.ast_analyzer = ASTAnalyzer()
        self.llm_reasoner = LLMReasoner()
    
    def detect(self) -> Dict[str, Any]:
        """
        NEW 3-Stage Flow:
        Stage 1: Rule Engine collects evidence
        Stage 2: AST Analyzer collects evidence  
        Stage 3: LLM makes final verdict based on combined evidence
        """
        # LAYER 1: Rule Engine - Collect evidence (Fast pattern matching ~10ms)
        layer1_evidence = self.rule_engine.detect_npc(self.code)
        
        # LAYER 2: AST Analyzer - Collect evidence (Structural verification ~50ms)
        layer2_evidence = self.ast_analyzer.verify_npc(self.code) if self.code_ast else None
        
        # LAYER 3: LLM makes final verdict based on Layer 1 & 2 evidence (~300ms)
        final_verdict = self.llm_reasoner.final_verdict(
            prompt=self.prompt,
            code=self.code,
            layer1_evidence=layer1_evidence,
            layer2_evidence=layer2_evidence,
            detector_type='npc'
        )
        
        return final_verdict
    
    def _pattern_based_detection(self) -> List[str]:
        """Check for common NPC patterns in code"""
        found = []
        
        for pattern, feature_name in self.NPC_PATTERNS.items():
            if pattern in self.code and pattern.lower() not in self.prompt_lower:
                found.append(feature_name)
        
        return found
    
    def _ast_based_detection(self) -> List[str]:
        """Use AST to detect structural NPC"""
        found = []
        
        # 1. Try-except blocks not mentioned
        try_blocks = [node for node in ast.walk(self.code_ast) if isinstance(node, ast.Try)]
        if try_blocks and 'error' not in self.prompt_lower and 'exception' not in self.prompt_lower:
            found.append("error handling not requested")
        
        # 2. Security/admin checks
        for node in ast.walk(self.code_ast):
            if isinstance(node, ast.If):
                try:
                    # Python 3.9+
                    if hasattr(ast, 'unparse'):
                        condition_str = ast.unparse(node.test).lower()
                    else:
                        condition_str = ""
                    
                    security_keywords = ['admin', 'auth', 'permission', 'role', 'authorized']
                    if any(kw in condition_str for kw in security_keywords):
                        if not any(kw in self.prompt_lower for kw in security_keywords):
                            found.append("security checks not requested")
                            break
                except:
                    pass
        
        # 3. Performance optimizations (decorators)
        for node in ast.walk(self.code_ast):
            if isinstance(node, ast.FunctionDef):
                for decorator in node.decorator_list:
                    if isinstance(decorator, ast.Name):
                        if 'cache' in decorator.id.lower() or 'memo' in decorator.id.lower():
                            if 'cache' not in self.prompt_lower and 'optimize' not in self.prompt_lower:
                                found.append("performance optimization not requested")
        
        # 4. Logging statements
        log_calls = 0
        for node in ast.walk(self.code_ast):
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Attribute):
                    if 'log' in node.func.attr.lower():
                        log_calls += 1
        
        if log_calls > 0 and 'log' not in self.prompt_lower:
            found.append("logging not requested")
        
        return found
    
    def _keyword_based_detection(self) -> List[str]:
        """Detect features in code not mentioned in prompt"""
        found = []
        
        # Extract code features
        code_keywords = self.keyword_extractor.extract_from_prompt(self.code)
        
        # Find code features not in prompt
        unprompted_keywords = code_keywords - self.prompt_keywords
        
        # Filter to significant additions only
        significant_additions = {
            'security', 'validation', 'optimization', 'caching', 
            'logging', 'monitoring', 'authentication'
        }
        
        for keyword in unprompted_keywords:
            if any(sig in keyword for sig in significant_additions):
                found.append(f"'{keyword}' feature not requested")
        
        return found



==================================================
File: app/analyzers/analyzers/linguistic/prompt_bias_detector.py
==================================================

"""
Detect hardcoded values from prompt examples (Prompt-Biased Code)
Enhanced with 3-layer evidence → LLM verdict architecture
"""
import re
import ast
from typing import Dict, Any, List
from .base_detector import BaseDetector
from .layers import RuleEngine, ASTAnalyzer, LLMReasoner


class PromptBiasDetector(BaseDetector):
    """Detect prompt-biased code (hardcoded example values) using 3-layer cascade"""
    
    def __init__(self, prompt: str, code: str, code_ast: ast.AST = None):
        super().__init__(prompt, code, code_ast)
        
        # Initialize 3-layer architecture (NO aggregator needed)
        self.rule_engine = RuleEngine()
        self.ast_analyzer = ASTAnalyzer()
        self.llm_reasoner = LLMReasoner()
    
    def detect(self) -> Dict[str, Any]:
        """
        NEW 3-Stage Flow:
        Stage 1: Rule Engine collects evidence
        Stage 2: AST Analyzer collects evidence  
        Stage 3: LLM makes final verdict based on combined evidence
        """
        # LAYER 1: Rule Engine - Collect evidence (Fast pattern matching ~10ms)
        layer1_evidence = self.rule_engine.detect_prompt_bias(self.code, self.prompt)
        
        # LAYER 2: AST Analyzer - Collect evidence (Structural verification ~50ms)
        layer2_evidence = self.ast_analyzer.verify_prompt_bias(self.code, self.prompt) if self.code_ast else None
        
        # LAYER 3: LLM makes final verdict based on Layer 1 & 2 evidence (~300ms)
        final_verdict = self.llm_reasoner.final_verdict(
            prompt=self.prompt,
            code=self.code,
            layer1_evidence=layer1_evidence,
            layer2_evidence=layer2_evidence,
            detector_type='prompt_bias'
        )
        
        return final_verdict
    
    def _detect_string_literals(self) -> List[str]:
        """Extract quoted strings from prompt and check if hardcoded"""
        hardcoded = []
        
        # Extract examples from prompt
        prompt_examples = []
        
        # Pattern 1: Quoted strings
        prompt_examples.extend(re.findall(r'["\']([^"\']{3,})["\']', self.prompt))
        
        # Pattern 2: "e.g., Example"
        prompt_examples.extend(re.findall(r'e\.g\.,?\s+["\']?([a-zA-Z_][a-zA-Z0-9_]{2,})["\']?', self.prompt, re.IGNORECASE))
        
        # Pattern 3: "for example: value"
        prompt_examples.extend(re.findall(r'example[:\s]+["\']?([a-zA-Z_][a-zA-Z0-9_]{2,})["\']?', self.prompt, re.IGNORECASE))
        
        # Pattern 4: "like 'value'"
        prompt_examples.extend(re.findall(r'like\s+["\']([^"\']+)["\']', self.prompt, re.IGNORECASE))
        
        # Check if examples are hardcoded in comparisons
        for example in prompt_examples:
            if example and len(example) > 2:
                # Check for hardcoded equality checks
                patterns = [
                    f'== "{example}"',
                    f"== '{example}'",
                    f'== {example}',
                    f'if "{example}"',
                    f"if '{example}'"
                ]
                
                if any(pattern in self.code for pattern in patterns):
                    hardcoded.append(f'string: "{example}"')
        
        return hardcoded
    
    def _detect_magic_numbers(self) -> List[str]:
        """Detect hardcoded numbers from prompt examples"""
        hardcoded = []
        
        # Extract numbers from prompt
        prompt_numbers = re.findall(r'\b(\d+)\b', self.prompt)
        
        # Check if these numbers appear in conditionals
        for num in set(prompt_numbers):
            # Skip common numbers (0, 1, 2)
            if int(num) <= 2:
                continue
            
            # Check if number is in a condition
            conditional_patterns = [
                f'== {num}',
                f'> {num}',
                f'< {num}',
                f'>= {num}',
                f'<= {num}',
                f'!= {num}'
            ]
            
            if any(pattern in self.code for pattern in conditional_patterns):
                hardcoded.append(f'magic number: {num}')
        
        return hardcoded
    
    def _detect_ast_comparisons(self) -> List[str]:
        """Use AST to find hardcoded comparisons"""
        hardcoded = []
        
        # Get all string constants from prompt
        prompt_strings = set(re.findall(r'["\']([^"\']{3,})["\']', self.prompt))
        
        # Find all comparison nodes in code
        for node in ast.walk(self.code_ast):
            if isinstance(node, ast.Compare):
                # Check if comparing with a constant
                for comparator in node.comparators:
                    if isinstance(comparator, ast.Constant):
                        value = comparator.value
                        
                        # If string constant matches prompt example
                        if isinstance(value, str) and value in prompt_strings:
                            hardcoded.append(f'hardcoded comparison: "{value}"')
                        
                        # If numeric constant from prompt
                        elif isinstance(value, (int, float)):
                            if str(value) in self.prompt:
                                hardcoded.append(f'hardcoded number in condition: {value}')
        
        return hardcoded



==================================================
File: app/analyzers/analyzers/linguistic/__init__.py
==================================================

"""
Linguistic Analysis Module for CodeGuard
Detects LLM-specific bugs through prompt-code comparison
"""

from .npc_detector import NPCDetector
from .prompt_bias_detector import PromptBiasDetector
from .missing_feature_detector import MissingFeatureDetector
from .misinterpretation_detector import MisinterpretationDetector

__all__ = [
    'NPCDetector',
    'PromptBiasDetector', 
    'MissingFeatureDetector',
    'MisinterpretationDetector'
]



==================================================
File: app/analyzers/analyzers/linguistic/layers/aggregator.py
==================================================

"""
Layer Aggregator
================
Intelligently combines results from all 3 layers using weighted voting and consensus.
Makes UI and automation decisions more reliable.
"""

import re
from typing import Dict, List, Any, Optional


class LayerAggregator:
    """
    Aggregates results from Rule Engine, AST Analyzer, and LLM Reasoner.
    
    Uses:
    - MAX confidence (highest confidence wins)
    - WEIGHTED severity (Layer 3 > Layer 2 > Layer 1)
    - CONSENSUS detection (all_agree > majority_agree > conflicting)
    """
    
    # Weights for severity calculation
    LAYER_WEIGHTS = {
        'layer1': 0.3,  # Rule Engine - 30% weight (fast but less accurate)
        'layer2': 0.3,  # AST Analyzer - 30% weight (structural verification)
        'layer3': 0.4,  # LLM Reasoner - 40% weight (most reliable semantic understanding)
    }
    
    def aggregate_findings(
        self, 
        layer1_result: Dict[str, Any], 
        layer2_result: Optional[Dict[str, Any]] = None,
        layer3_result: Optional[Dict[str, Any]] = None,
        finding_type: str = 'issues'
    ) -> Dict[str, Any]:
        """
        Aggregate results from all layers into a unified result.
        
        Args:
            layer1_result: Results from Rule Engine (always present)
            layer2_result: Results from AST Analyzer (optional)
            layer3_result: Results from LLM Reasoner (optional)
            finding_type: Type of findings ('issues', 'features', 'values', etc.)
        
        Returns:
            Aggregated result with:
            - overall_confidence: Max confidence from all layers
            - overall_severity: Weighted severity score
            - consensus: Agreement level between layers
            - findings: Combined findings from all layers
            - layers_detail: Individual layer results
        """
        layers = {
            'layer1': layer1_result,
            'layer2': layer2_result,
            'layer3': layer3_result
        }
        
        # Remove None layers
        active_layers = {k: v for k, v in layers.items() if v is not None}
        
        # Extract confidences
        confidences = []
        for layer_name, layer_data in active_layers.items():
            conf = layer_data.get('confidence', 0)
            if conf > 0:
                confidences.append(conf)
        
        # Overall confidence = MAX confidence (highest certainty wins)
        overall_confidence = max(confidences) if confidences else 0.0
        
        # Calculate weighted severity
        overall_severity = self._calculate_weighted_severity(active_layers)
        
        # Determine consensus
        consensus = self._determine_consensus(active_layers)
        
        # Aggregate findings from all layers with smart filtering
        all_findings = []
        for layer_name, layer_data in active_layers.items():
            issues = layer_data.get('issues', [])
            if issues:
                # Extract message from each issue
                for issue in issues:
                    if isinstance(issue, dict):
                        message = issue.get('message', str(issue))
                    else:
                        message = str(issue)
                    
                    # Filter out invalid "missing features" (code quality critiques)
                    if self._is_code_quality_critique(message):
                        continue  # Skip this finding
                    
                    if message and message not in all_findings:
                        all_findings.append(message)
        
        # Determine primary detection layer (highest confidence)
        primary_layer = self._get_primary_layer(active_layers)
        
        # Determine if found based on consensus
        found = self._determine_found_status(active_layers, consensus)
        
        return {
            'found': found,
            'findings': all_findings,
            'count': len(all_findings),
            'confidence': round(overall_confidence, 2),
            'severity': round(overall_severity, 2) if overall_severity > 0 else None,
            'consensus': consensus,
            'primary_detection': primary_layer,
            'layers_used': list(active_layers.keys()),
            'layers_detail': {
                k: {
                    'found': v.get('found', False),
                    'confidence': v.get('confidence', 0),
                    'issues_count': len(v.get('issues', []))
                }
                for k, v in active_layers.items()
            }
        }
    
    def _is_code_quality_critique(self, message: str) -> bool:
        \"\"\"
        Detect if a 'missing feature' is actually a code quality critique.
        
        These are NOT missing features:
        - \"Unnecessary X\" (critique of existing code)
        - \"Type validation performed only...\" (inconsistency in NPC, not missing feature)
        - \"Should use X instead of Y\" (best practice suggestion)
        - Anything mentioning \"unnecessary\", \"inconsistent\", \"should remove\"
        
        Returns True if it's a critique (should be filtered out)
        \"\"\"
        critique_patterns = [
            r'unnecessary',
            r'inconsistent',
            r'should remove',
            r'should not',
            r'too many',
            r'redundant',
            r'performed only',  # \"validation performed only on...\"
            r'applied only',    # \"check applied only to...\"
            r'without configuration',  # \"logging without configuration\"
            r'may clutter',      # \"may clutter output\"
            r'introduces overhead',  # performance critiques
        ]
        
        message_lower = message.lower()
        return any(re.search(pattern, message_lower) for pattern in critique_patterns)
    
    def _calculate_weighted_severity(self, layers: Dict[str, Dict]) -> float:
        """
        Calculate weighted severity across all layers.
        
        Uses configured weights:
        - Layer 1 (Rule Engine): 30%
        - Layer 2 (AST Analyzer): 30%
        - Layer 3 (LLM Reasoner): 40%
        """
        weighted_sum = 0.0
        total_weight = 0.0
        
        for layer_name, layer_data in layers.items():
            if layer_data.get('found', False):
                # Get severity (default to issue count if not specified)
                severity = layer_data.get('severity', len(layer_data.get('issues', [])))
                
                # Apply weight
                weight = self.LAYER_WEIGHTS.get(layer_name, 0.3)
                weighted_sum += severity * weight
                total_weight += weight
        
        # Return weighted average (or 0 if no layers found anything)
        return weighted_sum if total_weight > 0 else 0.0
    
    def _determine_consensus(self, layers: Dict[str, Dict]) -> str:
        """
        Determine consensus level between layers.
        
        Returns:
        - 'all_agree': All layers found the issue
        - 'majority_agree': 2/3 layers found the issue
        - 'single_layer': Only 1 layer found the issue
        - 'no_issues': No layers found any issues
        """
        found_count = sum(1 for layer in layers.values() if layer.get('found', False))
        total_layers = len(layers)
        
        if found_count == 0:
            return 'no_issues'
        elif found_count == total_layers:
            return 'all_agree'
        elif found_count >= 2:
            return 'majority_agree'
        else:
            return 'single_layer'
    
    def _get_primary_layer(self, layers: Dict[str, Dict]) -> str:
        """
        Determine which layer provided the primary detection.
        Returns layer with highest confidence.
        """
        max_confidence = 0.0
        primary_layer = 'layer1'
        
        for layer_name, layer_data in layers.items():
            confidence = layer_data.get('confidence', 0)
            if confidence > max_confidence:
                max_confidence = confidence
                primary_layer = layer_name
        
        return primary_layer
    
    def _determine_found_status(self, layers: Dict[str, Dict], consensus: str) -> bool:
        """
        Determine overall 'found' status based on consensus.
        
        Logic:
        - all_agree: True (high confidence)
        - majority_agree: True (medium confidence)
        - single_layer: True if it's Layer 3 (LLM), else check confidence
        - no_issues: False
        """
        if consensus in ['all_agree', 'majority_agree']:
            return True
        
        if consensus == 'single_layer':
            # If only Layer 3 found it, trust it (highest accuracy)
            if layers.get('layer3', {}).get('found', False):
                return True
            
            # Otherwise, check if confidence is high enough
            for layer_data in layers.values():
                if layer_data.get('found', False) and layer_data.get('confidence', 0) >= 0.9:
                    return True
        
        return False
    
    def calculate_reliability_score(self, consensus: str, confidence: float) -> str:
        """
        Calculate reliability score for UI display.
        
        Returns: 'very_high' | 'high' | 'medium' | 'low'
        """
        if consensus == 'all_agree' and confidence >= 0.95:
            return 'very_high'
        elif consensus in ['all_agree', 'majority_agree'] and confidence >= 0.85:
            return 'high'
        elif confidence >= 0.75:
            return 'medium'
        else:
            return 'low'
    
    def should_auto_fix(self, consensus: str, confidence: float, severity: float) -> bool:
        """
        Determine if issue is suitable for automatic fixing.
        
        Only auto-fix when:
        - High consensus (majority_agree or all_agree)
        - High confidence (>= 0.9)
        - Severity is significant (>= 5)
        """
        return (
            consensus in ['all_agree', 'majority_agree'] and
            confidence >= 0.9 and
            severity >= 5
        )



==================================================
File: app/analyzers/analyzers/linguistic/layers/layer1_rule_engine.py
==================================================

"""
Layer 1: Rule Engine
====================
Fast pattern matching using regex.
Returns preliminary findings in <10ms.
"""

import re
from typing import Dict, List, Any


class RuleEngine:
    """Fast regex-based pattern matching."""
    
    # NPC Patterns - Non-Prompted Considerations
    NPC_PATTERNS = {
        'debug_prints': [
            r'print\s*\(',
            r'console\.log\s*\(',
            r'debugger',
            r'import pdb',
            r'breakpoint\(\)',
        ],
        'logging': [
            r'logger\.',
            r'logging\.',
            r'\.debug\(',
            r'\.info\(',
            r'\.warning\(',
        ],
        'validation': [
            r'if\s+.*\s+is\s+None',
            r'if\s+not\s+',
            r'assert\s+',
            r'raise\s+',
        ],
        'error_handling': [
            r'try:',
            r'except\s+',
            r'finally:',
        ],
    }
    
    # Prompt Bias Patterns - Hardcoded examples
    EXAMPLE_PATTERNS = {
        'hardcoded_names': [
            r'\b(john|jane|alice|bob|test|example|sample|demo)\b',
            r'user123',
            r'test@',
        ],
        'hardcoded_numbers': [
            r'\b(123|456|789|42|100)\b(?!\s*(px|em|%|\))',  # Common example numbers
        ],
        'hardcoded_strings': [
            r'"hello\s*world"',
            r'"test"',
            r'"example"',
            r'"sample"',
        ],
    }
    
    # Missing Features - Action verbs that might indicate requirements
    ACTION_VERBS = [
        'create', 'add', 'delete', 'remove', 'update', 'edit',
        'save', 'load', 'fetch', 'get', 'set', 'send',
        'validate', 'verify', 'check', 'handle', 'process',
        'calculate', 'compute', 'sort', 'filter', 'search',
    ]
    
    def __init__(self):
        """Initialize the rule engine."""
        self.confidence = 0.95  # High confidence for pattern matches
    
    def detect_npc(self, code: str) -> Dict[str, Any]:
        """Detect NPC issues using patterns."""
        issues = []
        
        # Check for debug prints
        for pattern in self.NPC_PATTERNS['debug_prints']:
            if re.search(pattern, code, re.IGNORECASE):
                issues.append({
                    'type': 'debug_code',
                    'pattern': pattern,
                    'message': 'Debug/print statements found',
                    'confidence': self.confidence
                })
        
        # Check for logging
        for pattern in self.NPC_PATTERNS['logging']:
            if re.search(pattern, code, re.IGNORECASE):
                issues.append({
                    'type': 'logging',
                    'pattern': pattern,
                    'message': 'Logging statements found',
                    'confidence': self.confidence
                })
        
        return {
            'found': len(issues) > 0,
            'issues': issues,
            'layer': 'rule_engine',
            'confidence': self.confidence if issues else 0
        }
    
    def detect_prompt_bias(self, code: str, prompt: str = "") -> Dict[str, Any]:
        """Detect hardcoded examples from prompt."""
        issues = []
        
        # Extract potential examples from prompt
        if prompt:
            # Look for numbers in prompt, but exclude specifications like "return 0" or "default 0"
            prompt_lower = prompt.lower()
            
            # Skip numbers that are part of return value specifications
            specification_keywords = ['return', 'default', 'returns', 'output', 'result']
            
            prompt_numbers = re.findall(r'\b\d+\b', prompt)
            for num in prompt_numbers:
                # Check if this number is part of a specification (e.g., "return 0")
                is_specification = False
                for keyword in specification_keywords:
                    if re.search(rf'{keyword}\s+.*{num}', prompt_lower) or re.search(rf'{num}\s+.*{keyword}', prompt_lower):
                        is_specification = True
                        break
                
                if is_specification:
                    continue  # Skip numbers that are specifications, not examples
                
                # Check if this number appears in code (not in comments)
                code_clean = re.sub(r'#.*$', '', code, flags=re.MULTILINE)
                if re.search(rf'\b{num}\b', code_clean):
                    issues.append({
                        'type': 'hardcoded_number',
                        'value': num,
                        'message': f'Number {num} from prompt is hardcoded',
                        'confidence': 0.9
                    })
            
            # Look for names in prompt
            names = re.findall(r'\b[A-Z][a-z]+\b', prompt)
            for name in names:
                if re.search(rf'\b{name}\b', code, re.IGNORECASE):
                    issues.append({
                        'type': 'hardcoded_name',
                        'value': name,
                        'message': f'Example name "{name}" from prompt is hardcoded',
                        'confidence': 0.85
                    })
        
        # Check common example patterns
        for pattern in self.EXAMPLE_PATTERNS['hardcoded_names']:
            matches = re.findall(pattern, code, re.IGNORECASE)
            for match in matches:
                issues.append({
                    'type': 'example_data',
                    'value': match,
                    'message': f'Example data "{match}" found',
                    'confidence': 0.8
                })
        
        return {
            'found': len(issues) > 0,
            'issues': issues,
            'layer': 'rule_engine',
            'confidence': max([i['confidence'] for i in issues]) if issues else 0
        }
    
    def detect_missing_features(self, code: str, prompt: str) -> Dict[str, Any]:
        """Detect potentially missing features based on prompt.
        
        CONSERVATIVE APPROACH: Only report features that are:
        1. EXPLICITLY mentioned as requirements (not just action verbs)
        2. Clearly separate concerns (e.g., "validate email AND send notification")
        3. Not just different ways to express the same thing
        
        Skip detection if prompt is simple/minimal (< 10 words or single action).
        """
        issues = []
        
        # Skip for very simple prompts (likely don't have multiple explicit features)
        prompt_words = prompt.split()
        if len(prompt_words) < 10:
            # Too short to have multiple distinct feature requests
            return {
                'found': False,
                'issues': [],
                'layer': 'rule_engine',
                'confidence': 0
            }
        
        # Look for explicit feature lists (e.g., "do X and Y and Z")
        # Patterns: "X and Y", "X, Y, and Z", "X; Y; Z"
        explicit_features = re.findall(r'\band\b|,|;', prompt)
        
        if len(explicit_features) < 2:
            # No clear list of multiple features
            return {
                'found': False,
                'issues': [],
                'layer': 'rule_engine',
                'confidence': 0
            }
        
        # If we get here, prompt has multiple clauses - analyze carefully
        # This is very conservative - most simple prompts will return no missing features
        
        return {
            'found': False,  # Conservative: leave to LLM Layer 3 for complex cases
            'issues': issues,
            'layer': 'rule_engine',
            'confidence': 0
        }
    
    def detect_misinterpretation(self, code: str, prompt: str) -> Dict[str, Any]:
        """Basic pattern-based misinterpretation detection."""
        issues = []
        
        # CRITICAL: Check for print vs return mismatch
        # If prompt says "return" but code only prints
        if re.search(r'\breturn(s|ing)?\b', prompt.lower()):
            has_return = bool(re.search(r'return\s+(?!None)', code))
            has_print = bool(re.search(r'print\s*\(', code))
            
            if has_print and not has_return:
                issues.append({
                    'type': 'print_vs_return',
                    'expected': 'return',
                    'actual': 'print',
                    'message': 'Prompt asks to return but code uses print instead',
                    'confidence': 0.85  # High confidence for this pattern
                })
        
        # Check for return type mismatches (basic)
        if 'return a list' in prompt.lower() or 'return list' in prompt.lower():
            if not re.search(r'return\s*\[', code):
                issues.append({
                    'type': 'return_type_mismatch',
                    'expected': 'list',
                    'message': 'Prompt expects list return but code may return something else',
                    'confidence': 0.6  # Low confidence - AST should verify
                })
        
        if 'return a dict' in prompt.lower() or 'return dict' in prompt.lower():
            if not re.search(r'return\s*\{', code):
                issues.append({
                    'type': 'return_type_mismatch',
                    'expected': 'dict',
                    'message': 'Prompt expects dict return but code may return something else',
                    'confidence': 0.6
                })
        
        return {
            'found': len(issues) > 0,
            'issues': issues,
            'layer': 'rule_engine',
            'confidence': max([i['confidence'] for i in issues]) if issues else 0
        }    
    def detect_silly_mistakes(self, code: str, prompt: str) -> Dict[str, Any]:
        """Detect silly calculation/logic mistakes."""
        issues = []
        
        # CRITICAL: Check for wrong exponent in square/cube operations
        if re.search(r'\\bsquare\\b', prompt.lower()):
            # Looking for square - should be ** 2
            if re.search(r'\\*\\*\\s*3', code):  # Found ** 3 (cube)
                issues.append({
                    'type': 'wrong_exponent',
                    'expected': '** 2',
                    'actual': '** 3',
                    'message': 'Code uses ** 3 (cube) when prompt asks for square (** 2)',
                    'confidence': 0.95
                })
        
        if re.search(r'\\bcube\\b', prompt.lower()):
            # Looking for cube - should be ** 3
            if re.search(r'\\*\\*\\s*2', code):  # Found ** 2 (square)
                issues.append({
                    'type': 'wrong_exponent',
                    'expected': '** 3',
                    'actual': '** 2',
                    'message': 'Code uses ** 2 (square) when prompt asks for cube (** 3)',
                    'confidence': 0.95
                })
        
        # Check for wrong arithmetic operations
        if re.search(r'\\b(sum|add|total)\\b', prompt.lower()):
            # Expects addition but might use multiplication/subtraction
            if re.search(r'=\\s*\\w+\\s*\\*\\s*\\w+', code) and not re.search(r'\\+', code):
                issues.append({
                    'type': 'wrong_operation',
                    'expected': 'addition (+)',
                    'message': 'Prompt asks for sum/addition but code uses multiplication',
                    'confidence': 0.7
                })
        
        if re.search(r'\\b(average|mean)\\b', prompt.lower()):
            # Average needs division, check if missing
            if not re.search(r'/|len\\(', code):
                issues.append({
                    'type': 'missing_division',
                    'expected': 'division for average',
                    'message': 'Average calculation missing division by count',
                    'confidence': 0.8
                })
        
        return {
            'found': len(issues) > 0,
            'issues': issues,
            'layer': 'rule_engine',
            'confidence': max([i['confidence'] for i in issues]) if issues else 0
        }

if __name__ == "__main__":
    """Quick test"""
    engine = RuleEngine()
    
    test_code = """
def add_numbers(a, b):
    print(f"Debug: adding {a} and {b}")
    result = a + b
    return result

result = add_numbers(5, 3)
print(result)
"""
    
    test_prompt = "Create a function to add two numbers: 5 and 3"
    
    print("Testing Rule Engine...")
    print("\n1. NPC Detection:")
    npc = engine.detect_npc(test_code)
    print(f"Found: {npc['found']}, Issues: {len(npc['issues'])}")
    
    print("\n2. Prompt Bias Detection:")
    bias = engine.detect_prompt_bias(test_code, test_prompt)
    print(f"Found: {bias['found']}, Issues: {len(bias['issues'])}")
    
    print("\n3. Missing Features:")
    missing = engine.detect_missing_features(test_code, test_prompt)
    print(f"Found: {missing['found']}, Issues: {len(missing['issues'])}")



==================================================
File: app/analyzers/analyzers/linguistic/layers/layer2_ast_analyzer.py
==================================================

"""
Layer 2: AST Analyzer
=====================
Structural code analysis using Python AST.
Provides ground truth about code structure (~50ms).
"""

import ast
from typing import Dict, List, Any, Optional


class ASTAnalyzer:
    """Structural code analysis using Abstract Syntax Tree."""
    
    def __init__(self):
        """Initialize AST analyzer."""
        self.confidence = 1.0  # AST provides 100% structural accuracy
    
    def parse_code(self, code: str) -> Optional[ast.Module]:
        """Parse code into AST."""
        try:
            return ast.parse(code)
        except SyntaxError as e:
            print(f"Syntax error in code: {e}")
            return None
    
    def extract_function_calls(self, tree: ast.Module) -> List[Dict[str, Any]]:
        """Extract all function calls from AST."""
        calls = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                func_name = None
                
                if isinstance(node.func, ast.Name):
                    func_name = node.func.id
                elif isinstance(node.func, ast.Attribute):
                    func_name = node.func.attr
                
                if func_name:
                    calls.append({
                        'name': func_name,
                        'lineno': node.lineno if hasattr(node, 'lineno') else None
                    })
        
        return calls
    
    def extract_literals(self, tree: ast.Module) -> List[Dict[str, Any]]:
        """Extract all literal values (strings, numbers)."""
        literals = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Constant):
                literals.append({
                    'type': type(node.value).__name__,
                    'value': node.value,
                    'lineno': node.lineno if hasattr(node, 'lineno') else None
                })
        
        return literals
    
    def extract_imports(self, tree: ast.Module) -> List[str]:
        """Extract all imports."""
        imports = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ''
                for alias in node.names:
                    imports.append(f"{module}.{alias.name}" if module else alias.name)
        
        return imports
    
    def extract_functions(self, tree: ast.Module) -> List[Dict[str, Any]]:
        """Extract function definitions."""
        functions = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append({
                    'name': node.name,
                    'args': [arg.arg for arg in node.args.args],
                    'lineno': node.lineno,
                    'has_return': any(isinstance(n, ast.Return) for n in ast.walk(node))
                })
        
        return functions
    
    def verify_npc(self, code: str) -> Dict[str, Any]:
        """Verify NPC issues using AST."""
        tree = self.parse_code(code)
        if not tree:
            return {'found': False, 'issues': [], 'layer': 'ast', 'confidence': 0}
        
        issues = []
        calls = self.extract_function_calls(tree)
        
        # Check for print statements (confirmed by AST)
        print_calls = [c for c in calls if c['name'] == 'print']
        if print_calls:
            issues.append({
                'type': 'print_statement',
                'count': len(print_calls),
                'lines': [c['lineno'] for c in print_calls],
                'message': f'{len(print_calls)} print statement(s) found',
                'confidence': self.confidence
            })
        
        # Check for logging calls
        logging_calls = [c for c in calls if any(log in c['name'].lower() for log in ['log', 'debug', 'info', 'warning', 'error'])]
        if logging_calls:
            issues.append({
                'type': 'logging',
                'count': len(logging_calls),
                'message': f'{len(logging_calls)} logging call(s) found',
                'confidence': self.confidence
            })
        
        # Check for debugger imports
        imports = self.extract_imports(tree)
        debug_imports = [i for i in imports if any(d in i.lower() for d in ['pdb', 'debugger', 'ipdb'])]
        if debug_imports:
            issues.append({
                'type': 'debug_import',
                'imports': debug_imports,
                'message': f'Debug imports found: {", ".join(debug_imports)}',
                'confidence': self.confidence
            })
        
        return {
            'found': len(issues) > 0,
            'issues': issues,
            'layer': 'ast',
            'confidence': self.confidence if issues else 0
        }
    
    def verify_prompt_bias(self, code: str, prompt: str = "") -> Dict[str, Any]:
        """Verify hardcoded literals using AST."""
        tree = self.parse_code(code)
        if not tree:
            return {'found': False, 'issues': [], 'layer': 'ast', 'confidence': 0}
        
        issues = []
        literals = self.extract_literals(tree)
        
        # If we have a prompt, check for values from prompt
        if prompt:
            # Extract numbers from prompt
            import re
            prompt_numbers = re.findall(r'\b\d+\b', prompt)
            
            # Check if these numbers appear as literals
            for lit in literals:
                if lit['type'] in ['int', 'float']:
                    if str(lit['value']) in prompt_numbers:
                        issues.append({
                            'type': 'hardcoded_number',
                            'value': lit['value'],
                            'line': lit['lineno'],
                            'message': f'Number {lit["value"]} from prompt is hardcoded at line {lit["lineno"]}',
                            'confidence': self.confidence
                        })
        
        # Check for example strings
        example_patterns = ['test', 'example', 'sample', 'demo', 'hello world']
        for lit in literals:
            if lit['type'] == 'str' and lit['value']:
                value_lower = str(lit['value']).lower()
                for pattern in example_patterns:
                    if pattern in value_lower:
                        issues.append({
                            'type': 'example_string',
                            'value': lit['value'],
                            'line': lit['lineno'],
                            'message': f'Example string "{lit["value"]}" at line {lit["lineno"]}',
                            'confidence': 0.9
                        })
                        break
        
        return {
            'found': len(issues) > 0,
            'issues': issues,
            'layer': 'ast',
            'confidence': self.confidence if issues else 0
        }
    
    def verify_missing_features(self, code: str, prompt: str) -> Dict[str, Any]:
        """Verify if mentioned functions exist using AST.
        
        CONSERVATIVE: Only reports missing features for complex prompts with
        explicit multiple requirements. Simple prompts return no missing features.
        """
        tree = self.parse_code(code)
        if not tree:
            return {'found': False, 'issues': [], 'layer': 'ast', 'confidence': 0}
        
        # Conservative approach: Skip for simple prompts
        prompt_words = prompt.split()
        if len(prompt_words) < 15:
            # Simple prompt - don't look for missing features
            return {
                'found': False,
                'issues': [],
                'layer': 'ast',
                'confidence': 0
            }
        
        # For complex prompts, could analyze here, but leave to LLM Layer 3
        # Layer 2 focuses on structural verification, not semantic feature matching
        
        return {
            'found': False,
            'issues': [],
            'layer': 'ast',
            'confidence': 0
        }
    
    def analyze_return_type_mismatch(self, code: str, prompt: str) -> Dict[str, Any]:
        """Analyze return types vs prompt expectations."""
        tree = self.parse_code(code)
        if not tree:
            return {'found': False, 'issues': [], 'layer': 'ast', 'confidence': 0}
        
        issues = []
        
        # CRITICAL: Check for print vs return (AST verification)
        import re
        if re.search(r'\breturn(s|ing)?\b', prompt.lower()):
            has_return_statement = False
            has_print_statement = False
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Return) and node.value:
                    has_return_statement = True
                if isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name) and node.func.id == 'print':
                        has_print_statement = True
            
            if has_print_statement and not has_return_statement:
                issues.append({
                    'type': 'print_vs_return',
                    'expected': 'return statement',
                    'actual': 'print statement',
                    'message': 'Function prints output instead of returning it',
                    'confidence': self.confidence  # 100% confidence from AST
                })
        
        # Check what prompt expects
        expects_list = 'list' in prompt.lower() and 'return' in prompt.lower()
        expects_dict = 'dict' in prompt.lower() and 'return' in prompt.lower()
        
        # Analyze actual returns
        for node in ast.walk(tree):
            if isinstance(node, ast.Return) and node.value:
                return_type = None
                
                if isinstance(node.value, ast.List):
                    return_type = 'list'
                elif isinstance(node.value, ast.Dict):
                    return_type = 'dict'
                elif isinstance(node.value, ast.Constant):
                    return_type = type(node.value.value).__name__
                
                # Check mismatch
                if expects_list and return_type != 'list':
                    issues.append({
                        'type': 'return_type_mismatch',
                        'expected': 'list',
                        'actual': return_type,
                        'line': node.lineno,
                        'message': f'Expected list return but got {return_type} at line {node.lineno}',
                        'confidence': self.confidence
                    })
                
                if expects_dict and return_type != 'dict':
                    issues.append({
                        'type': 'return_type_mismatch',
                        'expected': 'dict',
                        'actual': return_type,
                        'line': node.lineno,
                        'message': f'Expected dict return but got {return_type} at line {node.lineno}',
                        'confidence': self.confidence
                    })
        
        return {
            'found': len(issues) > 0,
            'issues': issues,
            'layer': 'ast',
            'confidence': self.confidence if issues else 0
        }


if __name__ == "__main__":
    """Quick test"""
    analyzer = ASTAnalyzer()
    
    test_code = """
def add_numbers(a, b):
    print(f"Adding {a} and {b}")
    result = a + b
    return result

test_value = "example"
result = add_numbers(5, 3)
"""
    
    test_prompt = "Create a function to add 5 and 3"
    
    print("Testing AST Analyzer...")
    print("\n1. NPC Verification:")
    npc = analyzer.verify_npc(test_code)
    print(f"Found: {npc['found']}, Issues: {len(npc['issues'])}")
    for issue in npc['issues']:
        print(f"  - {issue['message']}")
    
    print("\n2. Prompt Bias Verification:")
    bias = analyzer.verify_prompt_bias(test_code, test_prompt)
    print(f"Found: {bias['found']}, Issues: {len(bias['issues'])}")
    for issue in bias['issues']:
        print(f"  - {issue['message']}")



==================================================
File: app/analyzers/analyzers/linguistic/layers/layer3_llm_reasoner.py
==================================================

"""
Layer 3: LLM Reasoner
====================
Semantic understanding using Dual LLM APIs:
- Primary: Ollama (local/cloud, free, fast)
- Fallback: OpenRouter (free tier, if Ollama fails)
Handles edge cases and nuanced interpretation (~300ms).
"""

import json
from typing import Dict, List, Any
from ..LLM_response import get_llm


class LLMReasoner:
    """AI-powered semantic analysis using Dual APIs (Ollama → OpenRouter fallback)."""
    
    def __init__(self):
        """Initialize LLM reasoner."""
        self.llm = get_llm()
        self.enabled = self.llm.enabled
        self.confidence = 0.98  # High confidence for AI analysis
        
        # Debug logging
        if self.enabled:
            print(f"✓ Layer 3 (LLM) ✅ Enabled - Using {'Ollama' if self.llm.ollama_enabled else ''} {'OpenRouter' if self.llm.openrouter_enabled else ''}")
        else:
            print("✗ Layer 3 (LLM) ❌ Disabled - No API keys configured")
    
    def deep_semantic_analysis(self, prompt: str, code: str, previous_findings: Dict = None) -> Dict[str, Any]:
        """
        Perform deep semantic analysis with context from previous layers.
        
        Args:
            prompt: User's original prompt
            code: Generated code
            previous_findings: Results from Layer 1 and Layer 2
        
        Returns:
            Dict with semantic analysis results
        """
        if not self.enabled:
            print("⚠️  Layer 3 (LLM) ❌ Skipped - No LLM APIs available")
            return {
                'found': False,
                'issues': [],
                'layer': 'llm',
                'confidence': 0,
                'message': 'LLM not enabled'
            }
        
        # Build context from previous findings
        context = ""
        if previous_findings:
            context = "\n\nPrevious Analysis Findings:\n"
            if previous_findings.get('rule_engine'):
                context += f"- Rule Engine: {len(previous_findings['rule_engine'].get('issues', []))} issues\n"
            if previous_findings.get('ast'):
                context += f"- AST Analysis: {len(previous_findings['ast'].get('issues', []))} issues\n"
        
        # Construct analysis prompt
        question = f"""You are a code analysis expert. Analyze this code for semantic bugs and misinterpretations.

USER'S ORIGINAL PROMPT:
{prompt}

GENERATED CODE:
```python
{code}
```{context}

CRITICAL DEFINITIONS - Read carefully before analyzing:

1. **NPC (Non-Prompted Consideration)**: Features/code added that were NOT requested
   - Example: User asks "add two numbers" but code includes logging, validation, type checking
   - Example: User asks "sort a list" but code includes caching, error handling, input sanitization
   - Report ONLY truly unrequested additions, not missing validations

2. **Prompt-Biased Code**: Using hardcoded values from prompt examples instead of general logic
   - Example: Prompt says "sort [3,1,2]" and code only works for those exact 3 numbers
   - Example: Using "test@example.com" as a hardcoded default instead of accepting any email

3. **Missing Features**: Features EXPLICITLY mentioned in prompt but NOT implemented
   - ONLY report if the feature was clearly requested in the original prompt
   - Example: Prompt says "validate email and phone" but code only validates email
   - DO NOT report general best practices (error handling, edge cases) unless explicitly requested
   - If prompt is simple (e.g., "add two numbers"), missing_features should be EMPTY []

4. **Misinterpretation**: Code does something fundamentally different from what was asked
   - Example: User asks to "remove duplicates" but code sorts instead
   - Example: User asks for "average" but code returns sum

STRICT RULES:
- Be conservative with "missing_features" - ONLY report explicitly requested items
- If the prompt is simple/minimal, missing_features should be [] or very short
- Don't confuse critiques of NPC with missing features
- Unrequested edge case handling = NPC, not a missing feature

Return ONLY valid JSON in this exact format:
{{
    "npc_issues": ["specific unrequested features found in code"],
    "prompt_bias_issues": ["hardcoded example values or logic"],
    "missing_features": ["features explicitly requested but not implemented - be conservative"],
    "misinterpretation": ["fundamental mismatches between request and implementation"],
    "severity": 0-10,
    "summary": "brief semantic analysis summary",
    "confidence": 0.0-1.0
}}"""
        
        try:
            result = self.llm.ask(question)
            
            if not result:
                return {
                    'found': False,
                    'issues': [],
                    'layer': 'llm',
                    'confidence': 0,
                    'error': 'No response from LLM'
                }
            
            # Try to parse JSON response
            try:
                # Extract JSON from markdown code blocks if present
                if '```json' in result:
                    result = result.split('```json')[1].split('```')[0].strip()
                elif '```' in result:
                    result = result.split('```')[1].split('```')[0].strip()
                
                analysis = json.loads(result)
                
                # Validate structure
                required_keys = ['npc_issues', 'prompt_bias_issues', 'missing_features', 'misinterpretation']
                if not all(k in analysis for k in required_keys):
                    raise ValueError("Missing required keys in LLM response")
                
                # Extract issues
                all_issues = []
                
                for npc in analysis.get('npc_issues', []):
                    all_issues.append({
                        'type': 'npc_semantic',
                        'message': npc,
                        'category': 'npc',
                        'confidence': analysis.get('confidence', self.confidence)
                    })
                
                for bias in analysis.get('prompt_bias_issues', []):
                    all_issues.append({
                        'type': 'prompt_bias_semantic',
                        'message': bias,
                        'category': 'prompt_bias',
                        'confidence': analysis.get('confidence', self.confidence)
                    })
                
                for missing in analysis.get('missing_features', []):
                    all_issues.append({
                        'type': 'missing_feature_semantic',
                        'message': missing,
                        'category': 'missing',
                        'confidence': analysis.get('confidence', self.confidence)
                    })
                
                for misint in analysis.get('misinterpretation', []):
                    all_issues.append({
                        'type': 'misinterpretation_semantic',
                        'message': misint,
                        'category': 'misinterpretation',
                        'confidence': analysis.get('confidence', self.confidence)
                    })
                
                return {
                    'found': len(all_issues) > 0,
                    'issues': all_issues,
                    'severity': analysis.get('severity', 0),
                    'summary': analysis.get('summary', ''),
                    'layer': 'llm',
                    'confidence': analysis.get('confidence', self.confidence),
                    'raw_response': result
                }
            
            except (json.JSONDecodeError, ValueError) as e:
                # LLM didn't return valid JSON, try to extract meaning
                return {
                    'found': True,
                    'issues': [{
                        'type': 'llm_analysis',
                        'message': result[:500],  # First 500 chars
                        'confidence': 0.7
                    }],
                    'layer': 'llm',
                    'confidence': 0.7,
                    'error': f'JSON parse error: {str(e)}',
                    'raw_response': result
                }
        
        except Exception as e:
            return {
                'found': False,
                'issues': [],
                'layer': 'llm',
                'confidence': 0,
                'error': str(e)
            }
    
    def final_verdict(self, prompt: str, code: str, layer1_evidence: Dict, layer2_evidence: Dict, detector_type: str) -> Dict[str, Any]:
        """
        LLM makes final verdict based on combined evidence from Layer 1 & 2.
        
        Args:
            prompt: User's original prompt
            code: Generated code
            layer1_evidence: Evidence from Rule Engine (Layer 1)
            layer2_evidence: Evidence from AST Analyzer (Layer 2)
            detector_type: 'npc' | 'prompt_bias' | 'missing_feature' | 'misinterpretation'
        
        Returns:
            Final verdict with all required fields
        """
        if not self.enabled:
            print(f"⚠️  Layer 3 (LLM) ❌ Skipped - No LLM APIs available")
            # Fallback to combined Layer 1 & 2 results
            return self._fallback_verdict(layer1_evidence, layer2_evidence, detector_type)
        
        # Build evidence summary
        evidence_summary = self._format_evidence(layer1_evidence, layer2_evidence)
        
        # Create targeted prompt based on detector type
        if detector_type == 'npc':
            question = self._create_npc_verdict_prompt(prompt, code, evidence_summary)
        elif detector_type == 'prompt_bias':
            question = self._create_prompt_bias_verdict_prompt(prompt, code, evidence_summary)
        elif detector_type == 'missing_feature':
            question = self._create_missing_feature_verdict_prompt(prompt, code, evidence_summary)
        elif detector_type == 'misinterpretation':
            question = self._create_misinterpretation_verdict_prompt(prompt, code, evidence_summary)
        else:
            raise ValueError(f"Unknown detector type: {detector_type}")
        
        try:
            result = self.llm.ask(question)
            
            if not result:
                return self._fallback_verdict(layer1_evidence, layer2_evidence, detector_type)
            
            # Parse JSON response
            try:
                if '```json' in result:
                    result = result.split('```json')[1].split('```')[0].strip()
                elif '```' in result:
                    result = result.split('```')[1].split('```')[0].strip()
                
                verdict = json.loads(result)
                
                # Format response based on detector type
                return self._format_verdict_response(verdict, detector_type)
            
            except (json.JSONDecodeError, ValueError) as e:
                print(f"⚠️  LLM JSON parse error: {e}")
                return self._fallback_verdict(layer1_evidence, layer2_evidence, detector_type)
        
        except Exception as e:
            print(f"⚠️  LLM error: {e}")
            return self._fallback_verdict(layer1_evidence, layer2_evidence, detector_type)
    
    def _format_evidence(self, layer1: Dict, layer2: Dict) -> str:
        """Format Layer 1 & 2 evidence for LLM."""
        evidence = []
        
        if layer1 and layer1.get('issues'):
            evidence.append(f"**Layer 1 (Rule Engine) Findings:**")
            evidence.append(f"- Found: {layer1.get('found', False)}")
            evidence.append(f"- Issues Count: {len(layer1.get('issues', []))}")
            evidence.append(f"- Confidence: {layer1.get('confidence', 0)}")
            for issue in layer1.get('issues', [])[:5]:  # Limit to 5
                evidence.append(f"  - {issue.get('message', issue)}")
        
        if layer2 and layer2.get('issues'):
            evidence.append(f"\n**Layer 2 (AST Analyzer) Findings:**")
            evidence.append(f"- Found: {layer2.get('found', False)}")
            evidence.append(f"- Issues Count: {len(layer2.get('issues', []))}")
            evidence.append(f"- Confidence: {layer2.get('confidence', 0)}")
            for issue in layer2.get('issues', [])[:5]:
                evidence.append(f"  - {issue.get('message', issue)}")
        
        return "\n".join(evidence) if evidence else "No evidence found by Layer 1 or Layer 2"
    
    def _create_npc_verdict_prompt(self, prompt: str, code: str, evidence: str) -> str:
        """Create LLM prompt for NPC detection verdict."""
        return f"""You are analyzing code for Non-Prompted Considerations (NPC).

**USER'S ORIGINAL PROMPT:**
{prompt}

**GENERATED CODE:**
```python
{code}
```

**EVIDENCE FROM PREVIOUS LAYERS:**
{evidence}

**YOUR TASK:**
Based on the evidence from Layer 1 (Rule Engine) and Layer 2 (AST Analyzer), make your final verdict.

**Definition of NPC:** Features or code added that were NOT explicitly requested in the prompt.
- Example: User asks "add two numbers" but code includes logging, validation, type checking
- Example: User asks "sort a list" but code includes caching, error handling

**Be conservative:** Only report truly unrequested additions, not missing validations.

Return JSON in this exact format:
{{
    "found": true/false,
    "features": ["list of unrequested features found"],
    "count": number_of_npc_issues,
    "confidence": 0.0-1.0,
    "severity": 0-10,
    "summary": "brief explanation"
}}"""
    
    def _create_prompt_bias_verdict_prompt(self, prompt: str, code: str, evidence: str) -> str:
        """Create LLM prompt for Prompt Bias detection verdict."""
        return f"""You are analyzing code for Prompt Bias (hardcoded example values).

**USER'S ORIGINAL PROMPT:**
{prompt}

**GENERATED CODE:**
```python
{code}
```

**EVIDENCE FROM PREVIOUS LAYERS:**
{evidence}

**YOUR TASK:**
Based on the evidence, determine if code uses hardcoded values from prompt examples instead of general logic.

**Definition of Prompt Bias:** Using specific example values from prompt as hardcoded defaults.
- Example: Prompt says "sort [3,1,2]" and code only works for those exact 3 numbers
- Example: Using "test@example.com" as hardcoded default instead of accepting any email

Return JSON in this exact format:
{{
    "found": true/false,
    "values": ["list of hardcoded values found"],
    "count": number_of_bias_issues,
    "confidence": 0.0-1.0,
    "severity": 0-10,
    "summary": "brief explanation"
}}"""
    
    def _create_missing_feature_verdict_prompt(self, prompt: str, code: str, evidence: str) -> str:
        """Create LLM prompt for Missing Feature detection verdict."""
        return f"""You are analyzing code for Missing Features.

**USER'S ORIGINAL PROMPT:**
{prompt}

**GENERATED CODE:**
```python
{code}
```

**EVIDENCE FROM PREVIOUS LAYERS:**
{evidence}

**YOUR TASK:**
Based on the evidence, determine what features were EXPLICITLY requested but NOT implemented.

**CRITICAL - BE EXTREMELY CONSERVATIVE:**
- ONLY report features that were EXPLICITLY and CLEARLY mentioned in the original prompt
- DO NOT report:
  - Type variations (e.g., returning 0.0 instead of 0 is fine for numeric functions)
  - General best practices (error handling, validation) unless EXPLICITLY requested
  - Defensive programming (None checks, type checking) unless EXPLICITLY requested
  - Edge case handling unless EXPLICITLY mentioned in prompt
- If the feature is implemented in a slightly different way but achieves the same goal, DO NOT report it
- When in doubt, DO NOT report it
- If prompt is simple (e.g., "add two numbers"), missing_features should be EMPTY []

**Example of what TO report:**
- Prompt: "validate email AND phone" → Code only validates email ← REPORT: Missing phone validation
- Prompt: "return both sum and product" → Code only returns sum ← REPORT: Missing product return

**Example of what NOT to report:**
- Prompt: "return 0" → Code returns 0.0 ← DO NOT REPORT: Same thing
- Prompt: "calculate average" → Code doesn't check for None ← DO NOT REPORT: Not requested
- Prompt: "add numbers" → No error handling ← DO NOT REPORT: Not requested

Return JSON in this exact format:
{{
    "found": true/false,
    "features": ["list of explicitly requested but missing features"],
    "count": number_of_missing_features,
    "confidence": 0.0-1.0,
    "severity": 0-10,
    "summary": "brief explanation"
}}"""
    
    def _create_misinterpretation_verdict_prompt(self, prompt: str, code: str, evidence: str) -> str:
        """Create LLM prompt for Misinterpretation detection verdict."""
        return f"""You are analyzing code for Fundamental Misinterpretation.

**USER'S ORIGINAL PROMPT:**
{prompt}

**GENERATED CODE:**
```python
{code}
```

**EVIDENCE FROM PREVIOUS LAYERS:**
{evidence}

**YOUR TASK:**
Based on the evidence, determine if code does something fundamentally different from what was asked.

**Definition of Misinterpretation:** Code does something fundamentally different from the request.
- Example: User asks to "remove duplicates" but code sorts instead
- Example: User asks for "average" but code returns sum
- Example: User asks for "factorial" but code returns fibonacci

Return JSON in this exact format:
{{
    "found": true/false,
    "reasons": ["list of misinterpretations found"],
    "score": 0-10 (severity),
    "confidence": 0.0-1.0,
    "severity": 0-10,
    "summary": "brief explanation"
}}"""
    
    def _format_verdict_response(self, verdict: Dict, detector_type: str) -> Dict[str, Any]:
        """Format LLM verdict into standard response format."""
        if detector_type == 'npc':
            return {
                'found': verdict.get('found', False),
                'features': verdict.get('features', []),
                'count': verdict.get('count', 0),
                'confidence': verdict.get('confidence', 0.98),
                'severity': verdict.get('severity', 0),
                'summary': verdict.get('summary', ''),
                'layers_used': ['layer1', 'layer2', 'layer3_llm'],
                'verdict_by': 'llm'
            }
        elif detector_type == 'prompt_bias':
            return {
                'found': verdict.get('found', False),
                'values': verdict.get('values', []),
                'count': verdict.get('count', 0),
                'confidence': verdict.get('confidence', 0.98),
                'severity': verdict.get('severity', 0),
                'summary': verdict.get('summary', ''),
                'layers_used': ['layer1', 'layer2', 'layer3_llm'],
                'verdict_by': 'llm'
            }
        elif detector_type == 'missing_feature':
            return {
                'found': verdict.get('found', False),
                'features': verdict.get('features', []),
                'count': verdict.get('count', 0),
                'confidence': verdict.get('confidence', 0.98),
                'severity': verdict.get('severity', 0),
                'summary': verdict.get('summary', ''),
                'layers_used': ['layer1', 'layer2', 'layer3_llm'],
                'verdict_by': 'llm'
            }
        elif detector_type == 'misinterpretation':
            return {
                'found': verdict.get('found', False),
                'reasons': verdict.get('reasons', []),
                'score': verdict.get('score', 0),
                'confidence': verdict.get('confidence', 0.98),
                'severity': verdict.get('severity', 0),
                'summary': verdict.get('summary', ''),
                'layers_used': ['layer1', 'layer2', 'layer3_llm'],
                'verdict_by': 'llm'
            }
    
    def _fallback_verdict(self, layer1: Dict, layer2: Dict, detector_type: str) -> Dict[str, Any]:
        """Fallback verdict when LLM is not available - combine Layer 1 & 2."""
        # Prefer Layer 2 (AST) over Layer 1 (Rules) when both available
        primary = layer2 if (layer2 and layer2.get('found')) else layer1
        
        if not primary or not primary.get('found'):
            # No bugs found
            if detector_type == 'npc':
                return {'found': False, 'features': [], 'count': 0, 'confidence': 0.95, 'severity': 0, 'layers_used': ['layer1', 'layer2'], 'verdict_by': 'fallback'}
            elif detector_type == 'prompt_bias':
                return {'found': False, 'values': [], 'count': 0, 'confidence': 0.95, 'severity': 0, 'layers_used': ['layer1', 'layer2'], 'verdict_by': 'fallback'}
            elif detector_type == 'missing_feature':
                return {'found': False, 'features': [], 'count': 0, 'confidence': 0.95, 'severity': 0, 'layers_used': ['layer1', 'layer2'], 'verdict_by': 'fallback'}
            elif detector_type == 'misinterpretation':
                return {'found': False, 'reasons': [], 'score': 0, 'confidence': 0.95, 'severity': 0, 'layers_used': ['layer1', 'layer2'], 'verdict_by': 'fallback'}
        
        # Combine findings from both layers
        combined_issues = []
        for layer in [layer1, layer2]:
            if layer and layer.get('issues'):
                for issue in layer.get('issues', []):
                    msg = issue.get('message', str(issue))
                    if msg not in combined_issues:
                        combined_issues.append(msg)
        
        confidence = max(
            layer1.get('confidence', 0) if layer1 else 0,
            layer2.get('confidence', 0) if layer2 else 0
        )
        
        if detector_type == 'npc':
            return {
                'found': True,
                'features': combined_issues,
                'count': len(combined_issues),
                'confidence': confidence,
                'severity': primary.get('severity', 5),
                'layers_used': ['layer1', 'layer2'],
                'verdict_by': 'fallback'
            }
        elif detector_type == 'prompt_bias':
            return {
                'found': True,
                'values': combined_issues,
                'count': len(combined_issues),
                'confidence': confidence,
                'severity': primary.get('severity', 5),
                'layers_used': ['layer1', 'layer2'],
                'verdict_by': 'fallback'
            }
        elif detector_type == 'missing_feature':
            return {
                'found': True,
                'features': combined_issues,
                'count': len(combined_issues),
                'confidence': confidence,
                'severity': primary.get('severity', 5),
                'layers_used': ['layer1', 'layer2'],
                'verdict_by': 'fallback'
            }
        elif detector_type == 'misinterpretation':
            return {
                'found': True,
                'reasons': combined_issues,
                'score': primary.get('severity', 5),
                'confidence': confidence,
                'severity': primary.get('severity', 5),
                'layers_used': ['layer1', 'layer2'],
                'verdict_by': 'fallback'
            }
    
    def verify_misinterpretation(self, prompt: str, code: str) -> Dict[str, Any]:
        """
        Focused analysis on whether code matches user intent.
        
        Args:
            prompt: User's prompt
            code: Generated code
        
        Returns:
            Dict with misinterpretation analysis
        """
        if not self.enabled:
            return {'found': False, 'issues': [], 'layer': 'llm', 'confidence': 0}
        
        question = f"""Does this code correctly implement what the user asked for?

USER ASKED FOR:
{prompt}

CODE GENERATED:
```python
{code}
```

Analyze if there's any misinterpretation:
1. Does the code do what was asked?
2. Are there assumptions that don't match the request?
3. Is the implementation approach appropriate?

Return JSON:
{{
    "correct_interpretation": true/false,
    "mismatches": ["list of intent mismatches"],
    "severity": 0-10
}}"""
        
        try:
            result = self.llm.ask(question)
            
            if result and '```json' in result:
                result = result.split('```json')[1].split('```')[0].strip()
            
            analysis = json.loads(result)
            
            issues = []
            for mismatch in analysis.get('mismatches', []):
                issues.append({
                    'type': 'intent_mismatch',
                    'message': mismatch,
                    'confidence': self.confidence
                })
            
            return {
                'found': len(issues) > 0,
                'issues': issues,
                'correct': analysis.get('correct_interpretation', True),
                'severity': analysis.get('severity', 0),
                'layer': 'llm',
                'confidence': self.confidence
            }
        
        except Exception as e:
            return {
                'found': False,
                'issues': [],
                'layer': 'llm',
                'confidence': 0,
                'error': str(e)
            }


if __name__ == "__main__":
    """Quick test"""
    reasoner = LLMReasoner()
    
    if not reasoner.enabled:
        print("LLM not enabled. Set OPENROUTER_API_KEY in .env")
        exit(1)
    
    test_code = """
def add_numbers(a, b):
    print(f"Adding {a} and {b}")
    return a + b

result = add_numbers(5, 3)
print(result)
"""
    
    test_prompt = "Create a function to add two numbers"
    
    print("Testing LLM Reasoner...")
    print("-" * 60)
    
    print("\nDeep Semantic Analysis:")
    analysis = reasoner.deep_semantic_analysis(test_prompt, test_code)
    print(f"Found: {analysis['found']}")
    print(f"Issues: {len(analysis.get('issues', []))}")
    print(f"Severity: {analysis.get('severity', 0)}/10")
    print(f"Summary: {analysis.get('summary', 'N/A')}")
    
    if analysis.get('issues'):
        print("\nDetailed Issues:")
        for issue in analysis['issues']:
            print(f"  - [{issue['category']}] {issue['message']}")
    
    print("-" * 60)



==================================================
File: app/analyzers/analyzers/linguistic/layers/__init__.py
==================================================

"""
NEW 3-Stage Analysis System
============================

Stage 1: Rule Engine - Fast pattern matching (evidence collection)
Stage 2: AST Analyzer - Structural verification (evidence collection)
Stage 3: LLM Reasoner - Final verdict based on combined evidence

No aggregator needed - LLM makes final decision based on all evidence.
"""

from .layer1_rule_engine import RuleEngine
from .layer2_ast_analyzer import ASTAnalyzer
from .layer3_llm_reasoner import LLMReasoner

__all__ = ['RuleEngine', 'ASTAnalyzer', 'LLMReasoner']



==================================================
File: app/analyzers/analyzers/linguistic/utils/ast_analyzer.py
==================================================

"""
Deep AST analysis utilities
"""
import ast
from typing import List, Set, Dict, Any


class ASTAnalyzer:
    """Advanced AST analysis for code features"""
    
    def __init__(self, code_ast: ast.AST):
        self.ast = code_ast
    
    def get_function_names(self) -> Set[str]:
        """Extract all function definitions"""
        if not self.ast:
            return set()
        
        functions = set()
        for node in ast.walk(self.ast):
            if isinstance(node, ast.FunctionDef):
                functions.add(node.name)
        return functions
    
    def get_function_calls(self) -> Set[str]:
        """Extract all function calls"""
        if not self.ast:
            return set()
        
        calls = set()
        for node in ast.walk(self.ast):
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name):
                    calls.add(node.func.id)
                elif isinstance(node.func, ast.Attribute):
                    calls.add(node.func.attr)
        return calls
    
    def get_imports(self) -> Set[str]:
        """Extract all imported modules"""
        if not self.ast:
            return set()
        
        imports = set()
        for node in ast.walk(self.ast):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.add(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.add(node.module)
                for alias in node.names:
                    imports.add(alias.name)
        return imports
    
    def has_try_except(self) -> bool:
        """Check if code has try-except blocks"""
        if not self.ast:
            return False
        
        for node in ast.walk(self.ast):
            if isinstance(node, ast.Try):
                return True
        return False
    
    def get_decorators(self) -> List[str]:
        """Extract all decorators used"""
        if not self.ast:
            return []
        
        decorators = []
        for node in ast.walk(self.ast):
            if isinstance(node, ast.FunctionDef):
                for decorator in node.decorator_list:
                    if isinstance(decorator, ast.Name):
                        decorators.append(decorator.id)
                    elif isinstance(decorator, ast.Attribute):
                        decorators.append(decorator.attr)
        return decorators
    
    def get_comparisons(self) -> List[Dict[str, Any]]:
        """Extract all comparison operations"""
        if not self.ast:
            return []
        
        comparisons = []
        for node in ast.walk(self.ast):
            if isinstance(node, ast.Compare):
                try:
                    # Get the comparison operators
                    ops = [op.__class__.__name__ for op in node.ops]
                    
                    # Get comparators if they're constants
                    values = []
                    for comparator in node.comparators:
                        if isinstance(comparator, ast.Constant):
                            values.append(comparator.value)
                    
                    if values:
                        comparisons.append({
                            'operators': ops,
                            'values': values
                        })
                except:
                    pass
        
        return comparisons
    
    def get_return_type_hints(self) -> Set[str]:
        """Extract return type annotations"""
        if not self.ast:
            return set()
        
        types = set()
        for node in ast.walk(self.ast):
            if isinstance(node, ast.FunctionDef):
                if node.returns:
                    if isinstance(node.returns, ast.Name):
                        types.add(node.returns.id)
                    elif isinstance(node.returns, ast.Subscript):
                        if isinstance(node.returns.value, ast.Name):
                            types.add(node.returns.value.id)
        return types
    
    def count_loops(self) -> Dict[str, int]:
        """Count different types of loops"""
        if not self.ast:
            return {'for': 0, 'while': 0}
        
        counts = {'for': 0, 'while': 0}
        for node in ast.walk(self.ast):
            if isinstance(node, ast.For):
                counts['for'] += 1
            elif isinstance(node, ast.While):
                counts['while'] += 1
        
        return counts
    
    def has_recursion(self) -> bool:
        """Check if any function calls itself"""
        if not self.ast:
            return False
        
        for node in ast.walk(self.ast):
            if isinstance(node, ast.FunctionDef):
                func_name = node.name
                for child in ast.walk(node):
                    if isinstance(child, ast.Call):
                        if isinstance(child.func, ast.Name):
                            if child.func.id == func_name:
                                return True
        return False



==================================================
File: app/analyzers/analyzers/linguistic/utils/keyword_extractor.py
==================================================

"""
Enhanced keyword extraction using multiple NLP techniques with lazy loading
"""
import re
import os
from typing import Set, List
from collections import Counter

# Force lightweight mode on low-memory environments (Render free tier)
DISABLE_HEAVY_NLP = os.getenv("DISABLE_HEAVY_NLP", "false").lower() == "true"

# Lazy loading for heavy models
SPACY_AVAILABLE = False
KEYBERT_AVAILABLE = False
NLTK_AVAILABLE = False

# Global references (loaded on first use)
nlp = None
keybert_model = None

# Check if libraries are installed (but don't load yet)
if not DISABLE_HEAVY_NLP:
    try:
        import spacy
        SPACY_AVAILABLE = True
    except ImportError:
        pass

    try:
        from keybert import KeyBERT
        KEYBERT_AVAILABLE = True
    except ImportError:
        pass

    try:
        import nltk
        from nltk.corpus import stopwords
        from nltk.tokenize import word_tokenize
        from nltk.stem import WordNetLemmatizer
        NLTK_AVAILABLE = True
    except ImportError:
        pass
else:
    print("⚠️  Heavy NLP disabled (DISABLE_HEAVY_NLP=true) - using regex fallback")


class KeywordExtractor:
    """Multi-strategy keyword extraction - with lazy loading to avoid slowdown"""
    
    def __init__(self):
        self.stop_words = self._get_stop_words()
        self.lemmatizer = None  # Lazy load when needed
        self._spacy_loaded = False
        self._keybert_loaded = False
    
    def _get_stop_words(self) -> Set[str]:
        """Get stop words from NLTK or fallback"""
        if NLTK_AVAILABLE:
            try:
                from nltk.corpus import stopwords
                return set(stopwords.words('english'))
            except:
                pass
        return {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to',
            'for', 'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are'
        }
    
    def extract_from_prompt(self, prompt: str, top_n: int = 20) -> Set[str]:
        """
        Extract keywords from prompt using best available method
        Priority: KeyBERT > spaCy > NLTK > Regex
        """
        # Try KeyBERT first (best for keyword extraction)
        if KEYBERT_AVAILABLE:
            return self._extract_with_keybert(prompt, top_n)
        
        # Fall back to spaCy
        elif SPACY_AVAILABLE:
            return self._extract_with_spacy(prompt)
        
        # Fall back to NLTK
        elif NLTK_AVAILABLE:
            return self._extract_with_nltk(prompt)
        
        # Last resort: regex
        else:
            return self._extract_with_regex(prompt)
    
    def _load_keybert(self):
        """Lazy load KeyBERT model (only on first use)"""
        global keybert_model
        if not self._keybert_loaded and keybert_model is None:
            try:
                from keybert import KeyBERT
                keybert_model = KeyBERT('all-MiniLM-L6-v2')
                self._keybert_loaded = True
            except Exception as e:
                print(f"Failed to load KeyBERT: {e}")
                self._keybert_loaded = False
    
    def _extract_with_keybert(self, text: str, top_n: int = 20) -> Set[str]:
        """
        Use KeyBERT for state-of-the-art keyword extraction
        Best for: Finding most relevant keywords automatically
        """
        try:
            self._load_keybert()
            if keybert_model:
                # Simple extraction (fast, no maxsum algorithm)
                keywords = keybert_model.extract_keywords(
                    text,
                    keyphrase_ngram_range=(1, 2),
                    stop_words='english',
                    top_n=top_n
                )
                return {kw[0].lower() for kw in keywords}
        except Exception as e:
            print(f"KeyBERT extraction failed: {e}")
        return self._extract_with_spacy(text)
    
    def _load_spacy(self):
        """Lazy load spaCy model (only on first use)"""
        global nlp
        if not self._spacy_loaded and nlp is None:
            try:
                import spacy
                nlp = spacy.load("en_core_web_sm")
                self._spacy_loaded = True
            except Exception as e:
                print(f"Failed to load spaCy: {e}")
                self._spacy_loaded = False
    
    def _extract_with_spacy(self, text: str) -> Set[str]:
        """
        Use spaCy for linguistic analysis
        Best for: Part-of-speech tagging, named entities
        """
        try:
            self._load_spacy()
            if nlp:
                doc = nlp(text.lower())
                keywords = set()
                
                for token in doc:
                    if token.pos_ == "VERB" and not token.is_stop:
                        keywords.add(token.lemma_)
                
                for token in doc:
                    if token.pos_ in ["NOUN", "PROPN"] and len(token.text) > 3:
                        keywords.add(token.lemma_)
                
                for ent in doc.ents:
                    keywords.add(ent.text.lower())
                
                for token in doc:
                    if token.pos_ == "ADJ" and len(token.text) > 4:
                        keywords.add(token.lemma_)
                
                return keywords
        except Exception as e:
            print(f"spaCy extraction failed: {e}")
        return self._extract_with_nltk(text)
    
    def _extract_with_nltk(self, text: str) -> Set[str]:
        """
        Use NLTK for traditional NLP
        Best for: Research, custom algorithms
        """
        if not NLTK_AVAILABLE:
            return self._extract_with_regex(text)
        
        try:
            if self.lemmatizer is None:
                from nltk.stem import WordNetLemmatizer
                self.lemmatizer = WordNetLemmatizer()
                try:
                    import nltk
                    nltk.data.find('corpora/stopwords')
                    nltk.data.find('tokenizers/punkt_tab')
                    nltk.data.find('corpora/wordnet')
                except LookupError:
                    nltk.download('stopwords', quiet=True)
                    nltk.download('punkt_tab', quiet=True)
                    nltk.download('punkt', quiet=True)
                    nltk.download('wordnet', quiet=True)
            
            from nltk.tokenize import word_tokenize
            tokens = word_tokenize(text.lower())
            
            keywords = {
                self.lemmatizer.lemmatize(token) 
                for token in tokens 
                if token.isalpha() and len(token) > 3 and token not in self.stop_words
            }
            
            try:
                import nltk
                pos_tags = nltk.pos_tag(tokens)
                filtered_keywords = {
                    self.lemmatizer.lemmatize(word)
                    for word, pos in pos_tags
                    if pos.startswith(('NN', 'VB', 'JJ')) and word in keywords
                }
                return filtered_keywords if filtered_keywords else keywords
            except:
                return keywords
        except Exception as e:
            print(f"NLTK extraction failed: {e}, falling back to regex")
            return self._extract_with_regex(text)
    
    def _extract_with_regex(self, text: str) -> Set[str]:
        """
        Fallback: Simple regex extraction (fast, no dependencies)
        Best for: When no NLP library available
        """
        words = re.findall(r'\b[a-z]+\b', text.lower())
        keywords = {
            w for w in words 
            if len(w) > 3 and w not in self.stop_words
        }
        return keywords
    
    def extract_action_verbs(self, text: str) -> Set[str]:
        """Extract programming action verbs specifically"""
        action_verbs = {
            'create', 'write', 'implement', 'calculate', 'compute', 'return',
            'get', 'fetch', 'retrieve', 'find', 'search', 'check', 'validate',
            'sort', 'filter', 'parse', 'process', 'handle', 'convert', 'format'
        }
        
        if SPACY_AVAILABLE:
            self._load_spacy()
            if nlp:
                doc = nlp(text.lower())
                found_verbs = {token.lemma_ for token in doc if token.pos_ == "VERB"}
                return found_verbs & action_verbs
        
        return {verb for verb in action_verbs if verb in text.lower()}
    
    def extract_data_types(self, text: str) -> Set[str]:
        """Extract mentioned data types"""
        data_types = {
            'list', 'dict', 'dictionary', 'string', 'str', 'int', 'integer',
            'float', 'number', 'tuple', 'array', 'set', 'bool', 'boolean'
        }
        return {dt for dt in data_types if dt in text.lower()}



==================================================
File: app/analyzers/analyzers/linguistic/utils/similarity_calculator.py
==================================================

"""
Calculate semantic similarity between prompt and code with lazy loading
"""
from typing import Tuple
import re
import os

# Force lightweight mode on low-memory environments (Render free tier)
DISABLE_HEAVY_NLP = os.getenv("DISABLE_HEAVY_NLP", "false").lower() == "true"

# Lazy loading for heavy models
SBERT_AVAILABLE = False
SKLEARN_AVAILABLE = False

# Global model reference (loaded on first use)
sbert_model = None

# Check if libraries are installed (but don't load yet)
if not DISABLE_HEAVY_NLP:
    try:
        from sentence_transformers import SentenceTransformer, util
        SBERT_AVAILABLE = True
    except ImportError:
        pass

    try:
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity
        SKLEARN_AVAILABLE = True
    except ImportError:
        pass
else:
    print("⚠️  Heavy NLP disabled (DISABLE_HEAVY_NLP=true) - using keyword overlap")


class SimilarityCalculator:
    """Calculate semantic similarity using multiple methods - with lazy loading"""
    
    def __init__(self):
        self._sbert_loaded = False
    
    def _load_sbert(self):
        """Lazy load Sentence-BERT model (only on first use)"""
        global sbert_model
        if not self._sbert_loaded and sbert_model is None:
            try:
                from sentence_transformers import SentenceTransformer
                sbert_model = SentenceTransformer('all-MiniLM-L6-v2')
                self._sbert_loaded = True
            except Exception as e:
                print(f"Failed to load SBERT: {e}")
                self._sbert_loaded = False
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """
        Calculate similarity using best available method
        Priority: Sentence-BERT > TF-IDF > Keyword Overlap
        """
        if SBERT_AVAILABLE:
            return self._sbert_similarity(text1, text2)
        elif SKLEARN_AVAILABLE:
            return self._tfidf_similarity(text1, text2)
        else:
            return self._keyword_overlap(text1, text2)
    
    def _sbert_similarity(self, text1: str, text2: str) -> float:
        """
        Use Sentence-BERT for semantic similarity
        Best method: Understands context and meaning
        """
        try:
            self._load_sbert()
            if sbert_model:
                from sentence_transformers import util
                embedding1 = sbert_model.encode(text1, convert_to_tensor=True)
                embedding2 = sbert_model.encode(text2, convert_to_tensor=True)
                similarity = util.cos_sim(embedding1, embedding2).item()
                return round(similarity, 3)
        except Exception as e:
            print(f"SBERT failed: {e}, falling back to TF-IDF")
        return self._tfidf_similarity(text1, text2)
    
    def _tfidf_similarity(self, text1: str, text2: str) -> float:
        """
        Use TF-IDF with cosine similarity
        Good for: Keyword-based matching
        """
        try:
            from sklearn.feature_extraction.text import TfidfVectorizer
            from sklearn.metrics.pairwise import cosine_similarity
            
            vectorizer = TfidfVectorizer(stop_words='english', max_features=100)
            tfidf_matrix = vectorizer.fit_transform([text1.lower(), text2.lower()])
            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
            return round(float(similarity), 3)
        except:
            return self._keyword_overlap(text1, text2)
    
    def _keyword_overlap(self, text1: str, text2: str) -> float:
        """
        Fallback: Simple keyword overlap (Jaccard similarity)
        Fast, no dependencies
        """
        words1 = set(re.findall(r'\b\w+\b', text1.lower()))
        words2 = set(re.findall(r'\b\w+\b', text2.lower()))
        
        words1 = {w for w in words1 if len(w) > 3}
        words2 = {w for w in words2 if len(w) > 3}
        
        if not words1:
            return 0.0
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return round(intersection / union if union > 0 else 0.0, 3)



==================================================
File: app/analyzers/analyzers/linguistic/utils/__init__.py
==================================================

"""
Utility modules for linguistic analysis
"""

from .keyword_extractor import KeywordExtractor
from .similarity_calculator import SimilarityCalculator
from .ast_analyzer import ASTAnalyzer

__all__ = ['KeywordExtractor', 'SimilarityCalculator', 'ASTAnalyzer']



==================================================
File: app/analyzers/analyzers/static/README.md
==================================================

# Static Analysis Module

## Overview

This module provides **organized static code analysis** for detecting various bug patterns in Python code. Each detector is isolated in its own file for better maintainability.

## Folder Structure

```
static/
├── __init__.py                    # Module exports
├── static_analyzer.py             # Main orchestrator
├── README.md                      # This file
└── detectors/                     # Individual detectors
    ├── __init__.py
    ├── syntax_detector.py         # Syntax errors (9/10)
    ├── hallucination_detector.py  # Undefined objects (8/10)
    ├── incomplete_detector.py     # Incomplete generation (7/10)
    ├── silly_mistake_detector.py  # Non-human patterns (6/10)
    ├── wrong_attribute_detector.py # Dict.key issues (7/10)
    ├── wrong_input_type_detector.py # Type mismatches (6/10)
    ├── prompt_bias_detector.py    # Hardcoded examples (variable)
    ├── npc_detector.py            # Unrequested features (variable)
    └── corner_case_detector.py    # Missing edge cases (5/10)
```

## Detectors

### 🔴 Critical (Severity 7-10)

1. **Syntax Error Detector** (9/10)
   - Detects Python syntax errors using AST parsing
   - Speed: <5ms
   - File: `syntax_detector.py`

2. **Hallucinated Object Detector** (8/10)
   - Detects undefined classes, functions, variables
   - Common with LLM-generated code
   - Speed: ~10ms
   - File: `hallucination_detector.py`

3. **Incomplete Generation Detector** (7/10)
   - Detects code that appears cut off or incomplete
   - Checks for empty assignments, incomplete loops, TODO markers
   - Speed: ~10ms
   - File: `incomplete_detector.py`

4. **Wrong Attribute Detector** (7/10)
   - Detects `dict.key` instead of `dict['key']`
   - Speed: ~5ms
   - File: `wrong_attribute_detector.py`

### 🟡 Medium-High (Severity 5-7)

5. **Silly Mistake Detector** (6/10)
   - Detects identical if/else branches
   - Detects reversed operands, type mismatches
   - Speed: ~10ms
   - File: `silly_mistake_detector.py`

6. **Wrong Input Type Detector** (6/10)
   - Detects string passed to `math.sqrt()`, etc.
   - Speed: ~10ms
   - File: `wrong_input_type_detector.py`

7. **Corner Case Detector** (5/10)
   - Detects missing critical edge case handling
   - Very conservative (only reports critical issues)
   - Speed: ~10ms
   - File: `corner_case_detector.py`

### 🟢 Variable Severity

8. **Prompt Bias Detector** (3-8/10)
   - Detects hardcoded example values from prompts
   - Speed: ~5ms
   - File: `prompt_bias_detector.py`

9. **NPC Detector** (3-6/10)
   - Detects non-prompted considerations
   - Very conservative
   - Speed: ~5ms
   - File: `npc_detector.py`

## Usage

### Basic Usage

```python
from app.analyzers.static import StaticAnalyzer

code = '''
def calculate_total(items)  # missing colon
    total = 0
    return total
'''

analyzer = StaticAnalyzer(code)
results = analyzer.analyze()

# Check for syntax errors
if results['syntax_error']['found']:
    print(f"Syntax error: {results['syntax_error']['error']}")

# Check for hallucinated objects
if results['hallucinated_objects']['found']:
    objects = results['hallucinated_objects']['objects']
    print(f"Undefined objects: {[obj['name'] for obj in objects]}")
```

### Individual Detector Usage

```python
from app.analyzers.static.detectors import SyntaxErrorDetector

detector = SyntaxErrorDetector(code)
result = detector.detect()

if result['found']:
    print(f"Syntax error at line {result['line']}: {result['error']}")
```

## Design Principles

1. **Modularity**: Each detector is independent and can be used standalone
2. **Fault Tolerance**: Individual detector failures don't crash the analysis
3. **Performance**: All detectors run in <20ms total
4. **Accuracy**: Conservative detection to minimize false positives
5. **Extensibility**: Easy to add new detectors

## Adding a New Detector

1. Create new file in `detectors/` folder
2. Implement detector class with `detect()` method
3. Add to `detectors/__init__.py`
4. Add to `static_analyzer.py` orchestrator
5. Update this README

### Template

```python
'''
New Detector
============
Brief description.

Pattern: Pattern Name
Severity: X/10
Speed: ~Xms
'''

from typing import Dict, Any


class NewDetector:
    """Detects specific pattern."""
    
    def __init__(self, code: str, tree: ast.AST = None):
        self.code = code
        self.tree = tree
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect pattern.
        
        Returns:
            Dict with detection results
        """
        return {
            "found": False,
            "details": []
        }
```

## Testing

Run the comprehensive test suite:

```bash
python backend/test/test_comprehensive_patterns.py
```

Test individual detectors:

```bash
python backend/app/analyzers/static/detectors/syntax_detector.py
```

## Performance

- **Total Analysis Time**: <50ms for most code
- **Syntax Error**: <5ms
- **Hallucination Detection**: ~10ms
- **Other Detectors**: <10ms each

## Migration from Old Structure

The detectors were previously in a single `static_analyzer.py` file. This new structure:
- ✅ Separates concerns
- ✅ Improves readability
- ✅ Makes testing easier
- ✅ Allows parallel development
- ✅ Reduces merge conflicts

The old `static_analyzer.py` in the parent folder can be deprecated once migration is complete.



==================================================
File: app/analyzers/analyzers/static/static_analyzer.py
==================================================

"""
Static Analyzer - Orchestrator
===============================
Coordinates all static analysis detectors.

This is the main entry point for static analysis.
It orchestrates individual detectors and aggregates results.
"""

import ast
from typing import Dict, Any

from .detectors.syntax_detector import SyntaxErrorDetector
from .detectors.hallucination_detector import HallucinatedObjectDetector
from .detectors.incomplete_detector import IncompleteGenerationDetector
from .detectors.silly_mistake_detector import SillyMistakeDetector
from .detectors.wrong_attribute_detector import WrongAttributeDetector
from .detectors.wrong_input_type_detector import WrongInputTypeDetector
from .detectors.prompt_bias_detector import PromptBiasDetector
from .detectors.npc_detector import NPCDetector
from .detectors.corner_case_detector import CornerCaseDetector


class StaticAnalyzer:
    """
    Orchestrates all static analysis detectors.
    
    Detectors run in parallel and results are aggregated.
    Fault-tolerant: individual detector failures don't crash the analysis.
    """
    
    def __init__(self, code: str):
        """
        Initialize static analyzer.
        
        Args:
            code: Source code to analyze
        """
        self.code = code
        self.lines = code.split('\n')
        self.tree = None
        
        # Try to parse once for all detectors
        syntax_detector = SyntaxErrorDetector(code)
        syntax_result = syntax_detector.detect()
        
        if not syntax_result.get('found'):
            self.tree = syntax_detector.tree
        else:
            # Get partial AST for use by other detectors
            self.tree = syntax_detector.get_partial_ast()
    
    def analyze(self) -> Dict[str, Any]:
        """
        Run all static analysis checks.
        
        Returns:
            Dict containing results from all detectors:
                - syntax_error: {...}
                - hallucinated_objects: {...}
                - incomplete_generation: {...}
                - silly_mistakes: {...}
                - wrong_attribute: {...}
                - wrong_input_type: {...}
                - prompt_biased: {...}
                - npc: {...}
                - missing_corner_case: {...}
        """
        results = {
            "syntax_error": self._run_detector(SyntaxErrorDetector, self.code),
            "hallucinated_objects": self._run_detector(HallucinatedObjectDetector, self.code, self.tree),
            "incomplete_generation": self._run_detector(IncompleteGenerationDetector, self.code, self.tree),
            "silly_mistakes": self._run_detector(SillyMistakeDetector, self.code, self.tree),
            "wrong_attribute": self._run_detector(WrongAttributeDetector, self.code),
            "wrong_input_type": self._run_detector(WrongInputTypeDetector, self.code, self.tree),
            "prompt_biased": self._run_detector(PromptBiasDetector, self.code),
            "npc": self._run_detector(NPCDetector, self.code),
            "missing_corner_case": self._run_detector(CornerCaseDetector, self.code, self.tree),
        }
        
        return results
    
    def _run_detector(self, detector_class, *args):
        """
        Run a detector with fault tolerance.
        
        Args:
            detector_class: Detector class to instantiate
            *args: Arguments to pass to detector
        
        Returns:
            Detection results or error dict
        """
        try:
            detector = detector_class(*args)
            return detector.detect()
        except Exception as e:
            return {
                "found": False,
                "error": f"{detector_class.__name__} failed: {str(e)}"
            }


if __name__ == "__main__":
    """Quick test"""
    test_code = """
def calculate_total(items)  # missing colon
    total = 0
    for item in items:
        total += item
    return total
"""
    
    analyzer = StaticAnalyzer(test_code)
    results = analyzer.analyze()
    
    print("Static Analysis Results:")
    print("=" * 60)
    
    for pattern, result in results.items():
        if result.get('found'):
            print(f"\n✗ {pattern.upper().replace('_', ' ')}")
            if 'details' in result:
                print(f"  Issues: {len(result['details'])}")
            elif 'objects' in result:
                print(f"  Objects: {len(result['objects'])}")
            elif 'error' in result:
                print(f"  Error: {result['error']}")
    
    print("\n" + "=" * 60)



==================================================
File: app/analyzers/analyzers/static/__init__.py
==================================================

"""
Static Analysis Module
======================
Organized static code analysis detectors for various bug patterns.
"""

from .static_analyzer import StaticAnalyzer

__all__ = ['StaticAnalyzer']



==================================================
File: app/analyzers/analyzers/static/detectors/corner_case_detector.py
==================================================

"""
Corner Case Detector
====================
Detects missing critical edge case handling (very conservative).

Pattern: Missing Corner Case
Severity: 5/10 (Medium)
Speed: ~10ms
"""

import ast
from typing import Dict, Any, List


class CornerCaseDetector:
    """Detects missing critical edge case handling."""
    
    def __init__(self, code: str, tree: ast.AST = None):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
            tree: Pre-parsed AST (optional)
        """
        self.code = code
        self.lines = code.split('\n')
        self.tree = tree
        if not self.tree:
            try:
                self.tree = ast.parse(code)
            except:
                pass
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect missing critical corner case handling.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - details: List[Dict] (line/function, description)
        """
        missing_cases = []
        
        # Only check for CRITICAL missing cases (division by zero)
        for i, line in enumerate(self.lines):
            # Skip comments and strings
            if line.strip().startswith('#'):
                continue
            
            # Check for division operations
            if '/' in line and '//' not in line and 'http://' not in line and 'https://' not in line:
                # Check wider context for protection
                context_start = max(0, i-5)
                context_end = min(len(self.lines), i+4)
                context_lines = '\n'.join(self.lines[context_start:context_end])
                
                # Look for protective checks in context
                has_protection = any([
                    '!= 0' in context_lines,
                    '== 0' in context_lines,
                    'if not numbers' in context_lines,
                    'if not items' in context_lines,
                    'if not data' in context_lines,
                    'if len(' in context_lines,
                    'ZeroDivisionError' in context_lines,
                    'try:' in context_lines and 'except' in context_lines,
                ])
                
                # Flag division by len() or count without protection
                if not has_protection:
                    if 'len(' in line or '.count(' in line:
                        missing_cases.append({
                            "line": i + 1,
                            "description": "Division operation without zero check"
                        })
        
        return {
            "found": len(missing_cases) > 0,
            "details": missing_cases
        }



==================================================
File: app/analyzers/analyzers/static/detectors/hallucination_detector.py
==================================================

"""
Hallucinated Object Detector
=============================
Detects references to undefined classes, functions, or variables
that may have been "hallucinated" by LLMs.

Pattern: Hallucinated Object
Severity: 8/10 (High)
Speed: ~10ms
"""

import ast
import re
from typing import Dict, Any, List, Set


class HallucinatedObjectDetector:
    """Detects undefined objects that LLMs sometimes invent."""
    
    # Hardcoded Python built-ins (reliable across platforms)
    BUILTINS = {
        # Built-in functions
        'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes',
        'callable', 'chr', 'classmethod', 'compile', 'complex', 'delattr',
        'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'filter',
        'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr',
        'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass',
        'iter', 'len', 'list', 'locals', 'map', 'max', 'memoryview', 'min',
        'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property',
        'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice',
        'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type',
        'vars', 'zip', '__import__',
        # Built-in constants
        'False', 'True', 'None', 'NotImplemented', 'Ellipsis', '__debug__',
    }
    
    COMMON_MODULES = {
        'math', 'os', 'sys', 're', 'json', 'time', 'datetime',
        'random', 'collections', 'itertools', 'functools', 'numpy', 'pandas',
        'logging', 'pathlib', 'io', 'typing', 'copy', 'pickle'
    }
    
    def __init__(self, code: str, tree: ast.AST = None):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
            tree: Pre-parsed AST (optional)
        """
        self.code = code
        self.lines = code.split('\n')
        self.tree = tree
        if not self.tree:
            try:
                self.tree = ast.parse(code)
            except:
                pass
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect potentially hallucinated objects.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - objects: List[Dict] (name, line, type)
        """
        hallucinated = []
        
        # Pattern 1: Class instantiations (CamelCase names)
        class_pattern = re.compile(r'([A-Z][a-zA-Z0-9]*)\s*\(')
        for i, line in enumerate(self.lines):
            stripped = line.strip()
            if stripped.startswith('#'):
                continue
            code_part = line.split('#')[0]
            matches = class_pattern.findall(code_part)
            for match in matches:
                if match not in self.BUILTINS and match not in self.COMMON_MODULES:
                    if not any(f'class {match}' in l for l in self.lines):
                        hallucinated.append({
                            "name": match,
                            "line": i + 1,
                            "type": "class"
                        })
        
        # Pattern 2: AST-based analysis
        if self.tree:
            defined_names = self._get_defined_names()
            used_names = self._get_used_names()
            
            for name in used_names:
                if name not in defined_names and name not in self.BUILTINS and name not in self.COMMON_MODULES:
                    if not any(h['name'] == name for h in hallucinated):
                        hallucinated.append({
                            "name": name,
                            "line": None,
                            "type": "variable"
                        })
        
        return {
            "found": len(hallucinated) > 0,
            "objects": hallucinated
        }
    
    def _get_defined_names(self) -> Set[str]:
        """Extract all defined names from AST."""
        defined = set()
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.FunctionDef):
                defined.add(node.name)
                # Add parameters
                for arg in node.args.args:
                    defined.add(arg.arg)
                for arg in node.args.kwonlyargs:
                    defined.add(arg.arg)
                if node.args.vararg:
                    defined.add(node.args.vararg.arg)
                if node.args.kwarg:
                    defined.add(node.args.kwarg.arg)
            elif isinstance(node, ast.ClassDef):
                defined.add(node.name)
            elif isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        defined.add(target.id)
            # Loop variables
            elif isinstance(node, ast.For):
                if isinstance(node.target, ast.Name):
                    defined.add(node.target.id)
                elif isinstance(node.target, ast.Tuple):
                    for elt in node.target.elts:
                        if isinstance(elt, ast.Name):
                            defined.add(elt.id)
            # With statement variables
            elif isinstance(node, ast.With):
                for item in node.items:
                    if item.optional_vars and isinstance(item.optional_vars, ast.Name):
                        defined.add(item.optional_vars.id)
            # Comprehension variables
            elif isinstance(node, (ast.ListComp, ast.SetComp, ast.DictComp, ast.GeneratorExp)):
                for generator in node.generators:
                    if isinstance(generator.target, ast.Name):
                        defined.add(generator.target.id)
                    elif isinstance(generator.target, ast.Tuple):
                        for elt in generator.target.elts:
                            if isinstance(elt, ast.Name):
                                defined.add(elt.id)
            # Imports
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    name = alias.asname if alias.asname else alias.name
                    defined.add(name)
            elif isinstance(node, ast.ImportFrom):
                for alias in node.names:
                    name = alias.asname if alias.asname else alias.name
                    defined.add(name)
        
        return defined
    
    def _get_used_names(self) -> Set[str]:
        """Extract all used names from AST."""
        used = set()
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Load):
                used.add(node.id)
        
        return used



==================================================
File: app/analyzers/analyzers/static/detectors/incomplete_detector.py
==================================================

"""
Incomplete Generation Detector
===============================
Detects code that appears to be incompletely generated
(LLM was cut off or reached token limits).

Pattern: Incomplete Generation
Severity: 7/10 (High)
Speed: ~10ms
"""

import ast
import re
from typing import Dict, Any, List


class IncompleteGenerationDetector:
    """Detects incomplete code generation patterns."""
    
    def __init__(self, code: str, tree: ast.AST = None):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
            tree: Pre-parsed AST (optional)
        """
        self.code = code
        self.lines = code.split('\n')
        self.tree = tree
        if not self.tree:
            try:
                self.tree = ast.parse(code)
            except:
                pass
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect incomplete code patterns.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - details: List[Dict] (type, line, description)
        """
        incomplete = []
        
        # Pattern 1: Empty assignments
        for i, line in enumerate(self.lines):
            if re.search(r'\w+\s*=\s*$', line.strip()):
                incomplete.append({
                    "type": "incomplete_assignment",
                    "line": i + 1,
                    "description": "Assignment with no value"
                })
        
        # Pattern 2: Functions with only pass or empty bodies
        if self.tree:
            for node in ast.walk(self.tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    if len(node.body) == 0:
                        incomplete.append({
                            "type": "empty_function",
                            "line": node.lineno,
                            "description": f"Function '{node.name}' has no body"
                        })
                    elif len(node.body) == 1 and isinstance(node.body[0], ast.Pass):
                        incomplete.append({
                            "type": "pass_only",
                            "line": node.lineno,
                            "description": f"Function '{node.name}' contains only 'pass'"
                        })
        
        # Pattern 3: Incomplete markers in comments
        for i, line in enumerate(self.lines):
            if '...' in line or 'TODO' in line or 'FIXME' in line:
                incomplete.append({
                    "type": "incomplete_marker",
                    "line": i + 1,
                    "description": "Code contains incomplete markers"
                })
            if '# missing' in line.lower() or '# stopped' in line.lower() or '# incomplete' in line.lower():
                incomplete.append({
                    "type": "incomplete_comment",
                    "line": i + 1,
                    "description": "Comment indicates incomplete code"
                })
        
        # Pattern 4: Incomplete loop logic
        if self.tree:
            incomplete.extend(self._detect_incomplete_loops())
        
        return {
            "found": len(incomplete) > 0,
            "details": incomplete
        }
    
    def _detect_incomplete_loops(self) -> List[Dict]:
        """Detect loops that appear incomplete (e.g., only one counter modified)."""
        issues = []
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.While):
                loop_vars = set()
                if isinstance(node.test, ast.Compare):
                    if isinstance(node.test.left, ast.Name):
                        loop_vars.add(node.test.left.id)
                    for comp in node.test.comparators:
                        if isinstance(comp, ast.Name):
                            loop_vars.add(comp.id)
                
                modified_vars = set()
                for stmt in ast.walk(node):
                    if isinstance(stmt, ast.AugAssign) and isinstance(stmt.target, ast.Name):
                        modified_vars.add(stmt.target.id)
                    elif isinstance(stmt, ast.Assign):
                        for target in stmt.targets:
                            if isinstance(target, ast.Name):
                                modified_vars.add(target.id)
                
                if len(loop_vars) >= 2 and len(modified_vars) == 1 and modified_vars.issubset(loop_vars):
                    issues.append({
                        "type": "incomplete_loop",
                        "line": node.lineno,
                        "description": f"While loop modifies only {modified_vars.pop()} but compares multiple variables"
                    })
        
        return issues



==================================================
File: app/analyzers/analyzers/static/detectors/npc_detector.py
==================================================

"""
NPC Detector (Static)
=====================
Detects non-prompted considerations (unrequested features).

Pattern: Non-Prompted Consideration (NPC)
Severity: Variable (3-6/10)
Speed: ~5ms
"""

from typing import Dict, Any, List


class NPCDetector:
    """Detects unrequested features in code."""
    
    def __init__(self, code: str):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
        """
        self.code = code
        self.lines = code.split('\n')
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect non-prompted considerations (very conservative).
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - details: List[Dict] (line, description)
        """
        npc_issues = []
        
        # Only detect obvious, unrequested additions
        for i, line in enumerate(self.lines):
            # Pattern 1: Security/auth checks not requested
            if 'raise' in line and any(word in line.lower() for word in ['admin', 'security', 'permission', 'auth']):
                npc_issues.append({
                    "line": i + 1,
                    "description": "Added security/authentication logic not requested"
                })
            
            # Pattern 2: Arbitrary threshold validation
            import re
            if re.search(r'if.*>\s*\d{3,}.*raise', line):
                npc_issues.append({
                    "line": i + 1,
                    "description": "Added arbitrary threshold validation not requested"
                })
        
        return {
            "found": len(npc_issues) > 0,
            "details": npc_issues
        }



==================================================
File: app/analyzers/analyzers/static/detectors/prompt_bias_detector.py
==================================================

"""
Prompt Bias Detector (Static)
==============================
Detects hardcoded values from prompt examples.

Pattern: Prompt-Biased Code
Severity: Variable (3-8/10)
Speed: ~5ms
"""

import re
from typing import Dict, Any, List


class PromptBiasDetector:
    """Detects hardcoded values from examples in prompts."""
    
    def __init__(self, code: str):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
        """
        self.code = code
        self.lines = code.split('\n')
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect hardcoded example values.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - details: List[Dict] (line, description)
        """
        biased_code = []
        
        # Look for example-specific patterns
        for i, line in enumerate(self.lines):
            # Pattern 1: Hardcoded example filenames with keywords
            if re.search(r'(==|!=)\s*["\'][^"\']*(demo|example|sample|test)[^"\']*["\']', line, re.IGNORECASE):
                biased_code.append({
                    "line": i + 1,
                    "description": "Hardcoded example filename in comparison"
                })
            
            # Pattern 2: Hardcoded "Example_" patterns
            elif re.search(r'==\s*["\']Example_', line):
                biased_code.append({
                    "line": i + 1,
                    "description": "Hardcoded check for example-specific value"
                })
        
        return {
            "found": len(biased_code) > 0,
            "details": biased_code
        }



==================================================
File: app/analyzers/analyzers/static/detectors/silly_mistake_detector.py
==================================================

"""
Silly Mistake Detector
======================
Detects non-human coding patterns like identical if/else branches,
reversed operands, or illogical operations.

Pattern: Silly Mistake
Severity: 6/10 (Medium-High)
Speed: ~10ms
"""

import ast
import re
from typing import Dict, Any, List


class SillyMistakeDetector:
    """Detects non-human coding patterns and silly mistakes."""
    
    def __init__(self, code: str, tree: ast.AST = None):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
            tree: Pre-parsed AST (optional)
        """
        self.code = code
        self.lines = code.split('\n')
        self.tree = tree
        if not self.tree:
            try:
                self.tree = ast.parse(code)
            except:
                pass
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect silly mistakes and non-human patterns.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - details: List[Dict] (type, line, description)
        """
        mistakes = []
        
        # Pattern 1: Reversed operands in calculations
        for i, line in enumerate(self.lines):
            if re.search(r'(discount|rate|percent)\s*-\s*(\w+)', line):
                mistakes.append({
                    "type": "reversed_operands",
                    "line": i + 1,
                    "description": "Suspicious operation: possible reversed operands"
                })
        
        # Pattern 2: String concatenation with non-string
        for i, line in enumerate(self.lines):
            if re.search(r'["\'].*["\']\s*\+\s*\w+(?!\()', line):
                if re.search(r'(rate|price|count|value|num)', line):
                    mistakes.append({
                        "type": "type_concatenation",
                        "line": i + 1,
                        "description": "Attempting string concatenation with likely numeric value"
                    })
        
        # Pattern 3: Identical if/else branches (AST-based)
        if self.tree:
            mistakes.extend(self._detect_identical_branches())
        
        return {
            "found": len(mistakes) > 0,
            "details": mistakes
        }
    
    def _detect_identical_branches(self) -> List[Dict]:
        """Detect if/else statements with identical code in both branches."""
        issues = []
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.If):
                if node.orelse and len(node.orelse) > 0:
                    try:
                        if_body_dump = [ast.dump(stmt) for stmt in node.body]
                        
                        # Skip elif chains
                        if len(node.orelse) == 1 and isinstance(node.orelse[0], ast.If):
                            continue
                        
                        else_body_dump = [ast.dump(stmt) for stmt in node.orelse]
                        
                        if if_body_dump == else_body_dump and len(if_body_dump) > 0:
                            issues.append({
                                "type": "identical_branches",
                                "line": node.lineno,
                                "description": "If and else branches contain identical code"
                            })
                    except:
                        continue
        
        return issues



==================================================
File: app/analyzers/analyzers/static/detectors/syntax_detector.py
==================================================

"""
Syntax Error Detector
=====================
Detects Python syntax errors using AST parsing.

Pattern: Syntax Error
Severity: 9/10 (Critical)
Speed: <5ms
"""

import ast
from typing import Dict, Any


class SyntaxErrorDetector:
    """Detects syntax errors in Python code."""
    
    def __init__(self, code: str):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
        """
        self.code = code
        self.tree = None
    
    def detect(self) -> Dict[str, Any]:
        """
        Check for syntax errors using AST parsing.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - error: str (if found)
                - line: int (if found)
                - offset: int (if found)
                - text: str (if found)
        """
        try:
            self.tree = ast.parse(self.code)
            return {
                "found": False,
                "error": None
            }
        except SyntaxError as e:
            return {
                "found": True,
                "error": str(e),
                "line": e.lineno,
                "offset": e.offset,
                "text": e.text
            }
        except Exception as e:
            return {
                "found": True,
                "error": f"Parse error: {str(e)}",
                "line": None,
                "offset": None,
                "text": None
            }
    
    def get_partial_ast(self) -> ast.AST:
        """
        Try to get a partial AST even if there are syntax errors.
        
        Returns:
            AST node or None
        """
        if self.tree:
            return self.tree
        
        # Try to parse by removing problematic lines
        lines = self.code.split('\n')
        for i in range(len(lines)):
            try:
                temp_lines = lines[:i] + lines[i+1:]
                temp_code = '\n'.join(temp_lines)
                return ast.parse(temp_code)
            except:
                continue
        return None



==================================================
File: app/analyzers/analyzers/static/detectors/wrong_attribute_detector.py
==================================================

"""
Wrong Attribute Detector
=========================
Detects incorrect attribute access patterns (e.g., dict.key instead of dict['key']).

Pattern: Wrong Attribute
Severity: 7/10 (High)
Speed: ~5ms
"""

import re
from typing import Dict, Any, List


class WrongAttributeDetector:
    """Detects wrong attribute access patterns."""
    
    def __init__(self, code: str):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
        """
        self.code = code
        self.lines = code.split('\n')
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect wrong attribute access patterns.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - details: List[Dict] (variable, attribute, line, description)
        """
        wrong_attrs = []
        
        # Pattern: dict.attribute instead of dict['key']
        # Common mistake: item.cost instead of item['cost']
        for i, line in enumerate(self.lines):
            dict_access = re.findall(r'(\w+)\.(\w+)', line)
            for var, attr in dict_access:
                # Common dict keys that are often accessed incorrectly
                if attr in ['cost', 'price', 'name', 'value', 'id', 'key', 'username', 'email']:
                    wrong_attrs.append({
                        "variable": var,
                        "attribute": attr,
                        "line": i + 1,
                        "description": f"Accessing '{attr}' as attribute instead of dictionary key"
                    })
        
        return {
            "found": len(wrong_attrs) > 0,
            "details": wrong_attrs
        }



==================================================
File: app/analyzers/analyzers/static/detectors/wrong_input_type_detector.py
==================================================

"""
Wrong Input Type Detector
==========================
Detects wrong input types passed to functions (e.g., string to math.sqrt()).

Pattern: Wrong Input Type
Severity: 6/10 (Medium-High)
Speed: ~10ms
"""

import ast
from typing import Dict, Any, List


class WrongInputTypeDetector:
    """Detects wrong input types in function calls."""
    
    # Functions that expect numeric input
    NUMERIC_FUNCTIONS = {
        'sqrt', 'pow', 'log', 'exp', 'sin', 'cos', 'tan',
        'ceil', 'floor', 'round', 'abs', 'int', 'float'
    }
    
    def __init__(self, code: str, tree: ast.AST = None):
        """
        Initialize detector.
        
        Args:
            code: Source code to analyze
            tree: Pre-parsed AST (optional)
        """
        self.code = code
        self.tree = tree
        if not self.tree:
            try:
                self.tree = ast.parse(code)
            except:
                pass
    
    def detect(self) -> Dict[str, Any]:
        """
        Detect wrong input types in function calls.
        
        Returns:
            Dict with detection results containing:
                - found: bool
                - details: List[Dict] (function, expected_type, actual_type, value, line, description)
        """
        wrong_types = []
        
        if not self.tree:
            return {"found": False, "details": []}
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.Call):
                func_name = None
                if isinstance(node.func, ast.Name):
                    func_name = node.func.id
                elif isinstance(node.func, ast.Attribute):
                    func_name = node.func.attr
                
                if func_name in self.NUMERIC_FUNCTIONS:
                    for arg in node.args:
                        if isinstance(arg, ast.Constant) and isinstance(arg.value, str):
                            wrong_types.append({
                                "function": func_name,
                                "expected_type": "numeric",
                                "actual_type": "string",
                                "value": arg.value,
                                "line": node.lineno,
                                "description": f"Passing string '{arg.value}' to numeric function {func_name}()"
                            })
        
        return {
            "found": len(wrong_types) > 0,
            "details": wrong_types
        }



==================================================
File: app/analyzers/analyzers/static/detectors/__init__.py
==================================================

"""
Static Analysis Detectors
==========================
Individual detector modules for specific bug patterns.
"""

from .syntax_detector import SyntaxErrorDetector
from .hallucination_detector import HallucinatedObjectDetector
from .incomplete_detector import IncompleteGenerationDetector
from .silly_mistake_detector import SillyMistakeDetector
from .wrong_attribute_detector import WrongAttributeDetector
from .wrong_input_type_detector import WrongInputTypeDetector
from .prompt_bias_detector import PromptBiasDetector
from .npc_detector import NPCDetector
from .corner_case_detector import CornerCaseDetector

__all__ = [
    'SyntaxErrorDetector',
    'HallucinatedObjectDetector',
    'IncompleteGenerationDetector',
    'SillyMistakeDetector',
    'WrongAttributeDetector',
    'WrongInputTypeDetector',
    'PromptBiasDetector',
    'NPCDetector',
    'CornerCaseDetector'
]


